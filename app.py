#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹Webåº”ç”¨ï¼ˆæ•´åˆç‰ˆæœ¬ï¼‰
"""

from flask import Flask, render_template, request, jsonify, Response, send_file
from flask_cors import CORS
import os
import json
import argparse
from typing import List
from pathlib import Path
import pandas as pd
from io import BytesIO
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn

# å¯¼å…¥æ•™å¸ˆç«¯å¤‡è¯¾æ¨¡å—
from teacher_planner import (
    collect_entities_llm,
    detect_intent_llm,
    call_hybrid_search,
    call_sports_meeting_search,
    generate_plan,
    generate_plan_stream,
    load_class_profiles,
)

# å¯¼å…¥ç­çº§æ•°æ®åˆ†ææ¨¡å—
from analyze_class_data import (
    analyze_class_file,
    analyze_with_llm,
    analyze_uploaded_file,
    get_all_class_profiles,
    delete_class_profile,
    update_class_profile,
)

app = Flask(__name__)
CORS(app)

# é…ç½®
SEARCH_BASE_URL = os.getenv("SEARCH_BASE_URL", "http://127.0.0.1:8001")


def gather_user_text(user_text: str, conversation_history: List[dict]) -> str:
    """æ”¶é›†ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯å†å²ä¸­çš„æ‰€æœ‰ç”¨æˆ·æ–‡æœ¬"""
    pieces: List[str] = []
    for msg in conversation_history or []:
        if msg.get("role") == "user":
            content = (msg.get("content") or "").strip()
            if content:
                pieces.append(content)
    if user_text:
        pieces.append(user_text.strip())
    return " ".join(pieces)


def detect_plan_type(current_text: str, conversation_history: List[dict]) -> str:
    """
    ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œåˆ¤æ–­æ˜¯å…¨å‘˜è¿åŠ¨ä¼šã€è¯¾è¯¾ç»ƒè¿˜æ˜¯é—²èŠ
    è¿”å›: "sports_meeting" | "lesson_plan" | "chat" | ""
    """
    try:
        intent = detect_intent_llm(current_text, conversation_history)
        # å¦‚æœæ˜¯chatï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆè¡¨ç¤ºä¸æ˜¯æ–¹æ¡ˆç”Ÿæˆæ„å›¾ï¼‰
        if intent == "chat":
            return ""
        return intent
    except Exception as e:
        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
        return ""


def get_local_ip():
    """è·å–æœ¬æœºIPåœ°å€"""
    import socket
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return "127.0.0.1"


# ==================== é¡µé¢è·¯ç”± ====================

@app.route('/')
def index():
    """ä¸»é¡µï¼šé‡å®šå‘åˆ°æ•™å¸ˆç«¯"""
    return render_template('teacher.html')


@app.route('/teacher')
def teacher():
    """æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹é¡µé¢"""
    return render_template('teacher.html')


@app.route('/class_data_manager')
def class_data_manager():
    """ç­çº§ä½“æµ‹æ•°æ®ç®¡ç†é¡µé¢"""
    return render_template('class_data_manager.html')


# ==================== æ•™å¸ˆç«¯å¤‡è¯¾API ====================

@app.route('/api/teacher/plan', methods=['POST'])
def teacher_plan():
    """
    æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹ï¼šå®ä½“æ”¶é›† -> å¤–éƒ¨æ£€ç´¢ -> æ–¹æ¡ˆç”Ÿæˆï¼ˆéæµå¼ï¼‰
    
    å…¥å‚ï¼š
      - message: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
      - conversation_history: å¯é€‰ï¼Œå¯¹è¯å†å²è®°å½•
      - override_params: å¯é€‰ï¼Œæ˜¾å¼æŒ‡å®šå‚æ•°
    
    è¿”å›ï¼š
      - å¦‚æœç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œè¿”å› need_more_info=True å’Œ ask æç¤ºè¯­
      - å¦åˆ™è¿”å›ç”Ÿæˆçš„æ–¹æ¡ˆ
    """
    try:
        data = request.get_json() or {}
        user_text = (data.get('message') or '').strip()
        conversation_history = data.get('conversation_history') or []
        override_params = data.get('override_params') or {}
        
        if not user_text and not override_params:
            return jsonify({'success': False, 'message': 'è¯·æä¾›messageæˆ–override_params'}), 400

        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æ”¶åˆ°è¯·æ±‚: user_text={user_text}, history_len={len(conversation_history)}")

        # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«
        plan_type = detect_plan_type(user_text, conversation_history)
        is_sports_meeting = plan_type == "sports_meeting"
        is_lesson_plan = plan_type == "lesson_plan"
        is_chat = not plan_type
        
        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æ„å›¾è¯†åˆ«: plan_type={plan_type}")

        # å®ä½“æŠ½å–
        try:
            params, missing = collect_entities_llm(user_text, conversation_history)
            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] å®ä½“æŠ½å–: params={params}, missing={missing}")
        except Exception as e:
            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] å®ä½“æŠ½å–å¤±è´¥: {e}")
            return jsonify({'success': False, 'message': f'å®ä½“æŠ½å–å¤±è´¥: {e}'}), 500

        # åº”ç”¨æ˜¾å¼è¦†ç›–
        for k in ['semantic_query', 'count_query', 'grades_query', 'trained_weaknesses', 'top_k']:
            if k in override_params and override_params[k] not in (None, ''):
                params[k] = override_params[k]
                if k in missing:
                    missing.remove(k)

        # æ·»åŠ æ„å›¾ç±»å‹åˆ°å‚æ•°ä¸­
        params["plan_type"] = plan_type or ""
        params["conversation_history"] = conversation_history

        # å¦‚æœæ˜¯é—²èŠï¼Œç›´æ¥ç”Ÿæˆå›å¤
        if is_chat:
            if os.getenv('DEBUG_AI','1')=='1':
                print("[TEACHER] è¯†åˆ«ä¸ºé—²èŠï¼Œç›´æ¥ç”Ÿæˆå›å¤")
            response_text = generate_plan([], params, user_text, need_guidance=False)
            conversation_history.append({"role": "user", "content": user_text})
            conversation_history.append({"role": "assistant", "content": response_text})
            return jsonify({
                'success': True,
                'response': response_text,
                'conversation_history': conversation_history,
                'is_chat': True
            })

        # åˆ¤æ–­æ˜¯å¦éœ€è¦å¼•å¯¼
        need_guidance = False
        missing_fields = []

        if is_sports_meeting:
            # å…¨å‘˜è¿åŠ¨ä¼šï¼šéœ€è¦æ“åœºæ¡ä»¶ã€å¹´çº§ã€äººæ•°ç­‰ä¿¡æ¯
            if not params.get("semantic_query") or not params.get("grades_query") or not params.get("count_query"):
                need_guidance = True
                if not params.get("semantic_query"):
                    missing_fields.append("semantic_query")
                if not params.get("grades_query"):
                    missing_fields.append("grades_query")
                if not params.get("count_query"):
                    missing_fields.append("count_query")
        elif is_lesson_plan:
            # è¯¾è¯¾ç»ƒï¼šéœ€è¦ç­çº§æˆ–è–„å¼±é¡¹ï¼Œæ»¡è¶³ä»»ä¸€å³å¯
            has_grades = bool(params.get("grades_query"))
            has_weaknesses = bool(params.get("trained_weaknesses"))
            if not has_grades and not has_weaknesses:
                need_guidance = True
                missing_fields.extend(["grades_query", "trained_weaknesses"])

        # å¦‚æœéœ€è¦å¼•å¯¼ï¼Œç”Ÿæˆå¼•å¯¼è¯­
        if need_guidance:
            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] éœ€è¦å¼•å¯¼ï¼Œç¼ºå¤±å­—æ®µ: {missing_fields}")
            guidance_text = generate_plan([], params, user_text, need_guidance=True)
            conversation_history.append({"role": "user", "content": user_text})
            conversation_history.append({"role": "assistant", "content": guidance_text})
            return jsonify({
                'success': True,
                'need_more_info': True,
                'ask': guidance_text,
                'conversation_history': conversation_history,
                'collected_params': params
            })

        # è°ƒç”¨æ£€ç´¢æ¥å£
        try:
            if is_sports_meeting:
                # å…¨å‘˜è¿åŠ¨ä¼šæ£€ç´¢
                semantic_with_text = f"{params.get('semantic_query', '')} {user_text}".strip()
                payload = {
                    "semantic_query": semantic_with_text,
                    "count_query": str(params.get("count_query") or ""),
                    "grades_query": str(params.get("grades_query") or ""),
                    "top_k": int(params.get("top_k") or 5),
                }
                results = call_sports_meeting_search(SEARCH_BASE_URL, payload)
            else:
                # è¯¾è¯¾ç»ƒæ£€ç´¢
                payload = {
                    "semantic_query": params.get("semantic_query") or "",
                    "count_query": str(params.get("count_query") or ""),
                    "grades_query": str(params.get("grades_query") or ""),
                    "trained_weaknesses": params.get("trained_weaknesses") or "",
                    "top_k": int(params.get("top_k") or 5),
                }
                results = call_hybrid_search(SEARCH_BASE_URL, payload)

            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")
                print("====== æ£€ç´¢ç»“æœåŸå§‹æ•°æ® ======")
                print(json.dumps(results, ensure_ascii=False, indent=2))
                print("====== æ£€ç´¢ç»“æœç»“æŸ ======")
        except Exception as e:
            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] æ£€ç´¢å¤±è´¥: {e}")
            results = []

        # ç”Ÿæˆæ–¹æ¡ˆ
        response_text = generate_plan(results, params, user_text, need_guidance=False)

        # æ›´æ–°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_text})
        conversation_history.append({"role": "assistant", "content": response_text})

        return jsonify({
            'success': True,
            'response': response_text,
            'conversation_history': conversation_history,
            'params': params,
            'results_count': len(results)
        })

    except Exception as e:
        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æ•™å¸ˆç«¯å¤‡è¯¾å¤±è´¥: {e}")
        return jsonify({'success': False, 'message': f'æ•™å¸ˆç«¯å¤‡è¯¾å¤±è´¥: {str(e)}'}), 500


@app.route('/api/teacher/plan/stream', methods=['POST'])
def teacher_plan_stream():
    """
    æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹ï¼šæµå¼è¾“å‡ºæ–¹æ¡ˆ

    å…¥å‚ï¼š
      - message: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
      - conversation_history: å¯é€‰ï¼Œå¯¹è¯å†å²è®°å½•
      - override_params: å¯é€‰ï¼Œæ˜¾å¼æŒ‡å®šå‚æ•°
    """
    try:
        data = request.get_json() or {}
        user_text = (data.get('message') or '').strip()
        conversation_history = data.get('conversation_history') or []
        override_params = data.get('override_params') or {}

        if not user_text and not override_params:
            return jsonify({'success': False, 'message': 'è¯·æä¾›messageæˆ–override_params'}), 400

        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æµå¼æ¥å£æ”¶åˆ°è¯·æ±‚: user_text={user_text}")

        # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«
        plan_type = detect_plan_type(user_text, conversation_history)
        is_sports_meeting = plan_type == "sports_meeting"
        is_lesson_plan = plan_type == "lesson_plan"
        is_chat = not plan_type

        # å®ä½“æŠ½å–
        params, missing = collect_entities_llm(user_text, conversation_history)

        # åº”ç”¨æ˜¾å¼è¦†ç›–
        for k in ['semantic_query', 'count_query', 'grades_query', 'trained_weaknesses', 'top_k']:
            if k in override_params and override_params[k] not in (None, ''):
                params[k] = override_params[k]

        # æ·»åŠ æ„å›¾ç±»å‹åˆ°å‚æ•°ä¸­
        params["plan_type"] = plan_type or ""
        params["conversation_history"] = conversation_history

        # å¦‚æœæ˜¯é—²èŠï¼Œç›´æ¥ç”Ÿæˆå‹å¥½å›å¤ï¼ˆæµå¼ï¼‰
        if is_chat:
            if os.getenv('DEBUG_AI','1')=='1':
                print("[TEACHER] æµå¼æ¥å£ï¼šè¯†åˆ«ä¸ºé—²èŠï¼Œç›´æ¥ç”Ÿæˆå›å¤")
            need_guidance = False
            missing_fields = []
        else:
            # å…³é”®æ£€æŸ¥ï¼šæ ¹æ®åœºæ™¯åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
            count_query = params.get('count_query')
            grades_query = params.get('grades_query')
            semantic_query = params.get('semantic_query')
            trained_weaknesses_value = params.get('trained_weaknesses')

            missing_fields = []
            if is_sports_meeting:
                # å…¨å‘˜è¿åŠ¨ä¼šï¼šéœ€è¦æ“åœºæ¡ä»¶ã€å¹´çº§ã€äººæ•°ç­‰ä¿¡æ¯
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šå…¨å‘˜è¿åŠ¨ä¼šåœºæ™¯ï¼Œæ£€æŸ¥å¿…è¦å­—æ®µ - semantic={semantic_query}, grades={grades_query}, count={count_query}")
                if not semantic_query:
                    missing_fields.append('semantic_query')
                if not grades_query:
                    missing_fields.append('grades_query')
                if not count_query:
                    missing_fields.append('count_query')
                if missing_fields and os.getenv('DEBUG_AI','1')=='1':
                    print("[TEACHER] æµå¼æ¥å£ï¼šâš ï¸ å…¨å‘˜è¿åŠ¨ä¼šåœºæ™¯ä¿¡æ¯ä¸å…¨ï¼Œè¿›å…¥å¼•å¯¼æµç¨‹ï¼Œç¼ºå¤±=", missing_fields)
            elif is_lesson_plan:
                # è¯¾è¯¾ç»ƒï¼šéœ€è¦ç­çº§ï¼ˆgrades_queryï¼‰æˆ–å¼±é¡¹ï¼ˆtrained_weaknessesï¼‰ï¼Œæ»¡è¶³ä»»ä¸€å³å¯
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šè¯¾è¯¾ç»ƒåœºæ™¯ï¼Œæ£€æŸ¥å¿…è¦å­—æ®µ - grades={grades_query}, trained_weaknesses={trained_weaknesses_value}")
                has_grades = bool(grades_query)
                has_weaknesses = bool(trained_weaknesses_value)
                if not has_grades and not has_weaknesses:
                    # ä¸¤ä¸ªéƒ½æ²¡æœ‰ï¼Œéœ€è¦å¼•å¯¼
                    missing_fields.append('grades_query_or_trained_weaknesses')
                if missing_fields and os.getenv('DEBUG_AI','1')=='1':
                    print("[TEACHER] æµå¼æ¥å£ï¼šâš ï¸ è¯¾è¯¾ç»ƒåœºæ™¯ä¿¡æ¯ä¸å…¨ï¼ˆç¼ºå°‘ç­çº§æˆ–å¼±é¡¹ï¼‰ï¼Œè¿›å…¥å¼•å¯¼æµç¨‹")

            need_guidance = bool(missing_fields)

        # å¦‚æœæ˜¯é—²èŠï¼Œç›´æ¥ç”Ÿæˆå‹å¥½å›å¤ï¼ˆæµå¼ï¼‰
        if is_chat:
            def chat_stream():
                try:
                    model = OptimizedAIModel()
                    chat_messages = [
                        {"role": "system", "content": TEACHER_SYSTEM_PROMPT},
                        {"role": "user", "content": f"ç”¨æˆ·è¯´ï¼š{user_text}\n\nè¯·ç”¨å‹å¥½ã€ç®€æ´çš„æ–¹å¼å›å¤ç”¨æˆ·ã€‚å¦‚æœæ˜¯è¯¢é—®åŠŸèƒ½ï¼Œå¯ä»¥ä»‹ç»ä½ å¯ä»¥å¸®åŠ©ç”Ÿæˆè¯¾è¯¾ç»ƒå¤‡è¯¾æ–¹æ¡ˆå’Œå…¨å‘˜è¿åŠ¨ä¼šæ–¹æ¡ˆã€‚"}
                    ]
                    stream = model.client.chat.completions.create(
                        model=model.model,
                        messages=chat_messages,
                        max_tokens=200,
                        temperature=0.7,
                        stream=True,
                    )
                    for event in stream:
                        try:
                            delta = event.choices[0].delta
                            content = getattr(delta, "content", None)
                            if content:
                                yield content
                        except Exception:
                            chunk = None
                            try:
                                chunk = event["choices"][0]["delta"].get("content")
                            except Exception:
                                pass
                            if chunk:
                                yield chunk
                except Exception as e:
                    if os.getenv('DEBUG_AI','1')=='1':
                        print(f"[TEACHER] æµå¼æ¥å£ï¼šé—²èŠå›å¤ç”Ÿæˆå¤±è´¥: {e}")
                    yield "æ‚¨å¥½ï¼æˆ‘æ˜¯AIå¤‡è¯¾åŠ©ç†ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ç”Ÿæˆè¯¾è¯¾ç»ƒå¤‡è¯¾æ–¹æ¡ˆå’Œå…¨å‘˜è¿åŠ¨ä¼šæ–¹æ¡ˆã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ã€‚"

            return Response(chat_stream(), mimetype='text/plain; charset=utf-8')

        if need_guidance:
            # ä¿¡æ¯ä¸å…¨ï¼Œä½¿ç”¨generate_plan_streamç”Ÿæˆå¼•å¯¼è¯­
            collected_so_far = {
                'semantic_query': params.get('semantic_query') or '',
                'count_query': params.get('count_query') or '',
                'grades_query': params.get('grades_query') or '',
                'trained_weaknesses': params.get('trained_weaknesses') or '',
                'plan_type': params.get('plan_type') or '',
                'top_k': int(params.get('top_k') or 5),
            }

            try:
                if os.getenv('DEBUG_AI','1')=='1':
                    print("[TEACHER] æµå¼æ¥å£ï¼šä¿¡æ¯ä¸å…¨ï¼Œè°ƒç”¨generate_plan_streamç”Ÿæˆå¼•å¯¼è¯­(æµå¼)...")

                def guidance_stream():
                    ask_chunks = []
                    try:
                        for chunk in generate_plan_stream([], params, user_text, need_guidance=True):
                            ask_chunks.append(chunk)
                            yield chunk

                        final_ask = "".join(ask_chunks).strip()

                        if os.getenv('DEBUG_AI','1')=='1':
                            print("[TEACHER] æµå¼æ¥å£ï¼šå¼•å¯¼è¯­æ¨é€å®Œæˆï¼Œé•¿åº¦=", len(final_ask))
                    except Exception as stream_err:
                        if os.getenv('DEBUG_AI','1')=='1':
                            print("[TEACHER] æµå¼æ¥å£ï¼šå¼•å¯¼è¯­æµå¼æ¨é€å¼‚å¸¸:", stream_err)
                        yield f"[å¼•å¯¼æµé”™è¯¯] {stream_err}"

                resp = Response(guidance_stream(), mimetype='text/plain; charset=utf-8')
                resp.headers['X-Need-More-Info'] = '1'
                # HTTPå“åº”å¤´åªèƒ½ä½¿ç”¨ASCIIå­—ç¬¦ï¼Œéœ€è¦å°†ä¸­æ–‡è½¬ä¹‰ä¸º\uXXXXæ ¼å¼
                resp.headers['X-Collected-Params'] = json.dumps(collected_so_far, ensure_ascii=True)
                return resp
            except Exception as e:
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šå¼•å¯¼è¯­æµå¼ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å…œåº•æç¤ºã€‚é”™è¯¯: {e}")

                def fallback_stream():
                    yield "è¯·è¯´æ˜éœ€è¦é‡ç‚¹æå‡çš„è–„å¼±é¡¹ï¼ˆå¦‚ï¼šé€Ÿåº¦/åŠ›é‡/æŸ”éŸ§/çµæ•/è€åŠ›/æ ¸å¿ƒç¨³å®š/åè°ƒ/å¹³è¡¡ï¼‰"

                resp = Response(fallback_stream(), mimetype='text/plain; charset=utf-8')
                resp.headers['X-Need-More-Info'] = '1'
                # HTTPå“åº”å¤´åªèƒ½ä½¿ç”¨ASCIIå­—ç¬¦ï¼Œéœ€è¦å°†ä¸­æ–‡è½¬ä¹‰ä¸º\uXXXXæ ¼å¼
                resp.headers['X-Collected-Params'] = json.dumps(collected_so_far, ensure_ascii=True)
                return resp

        # è°ƒç”¨æ£€ç´¢æ¥å£
        try:
            if is_sports_meeting:
                # å…¨å‘˜è¿åŠ¨ä¼šæ£€ç´¢
                semantic_with_text = f"{params.get('semantic_query', '')} {user_text}".strip()
                payload = {
                    "semantic_query": semantic_with_text,
                    "count_query": str(params.get("count_query") or ""),
                    "grades_query": str(params.get("grades_query") or ""),
                    "top_k": int(params.get("top_k") or 5),
                }
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šä½¿ç”¨å…¨å‘˜è¿åŠ¨ä¼šæ£€ç´¢ payload={payload}")
                results = call_sports_meeting_search(SEARCH_BASE_URL, payload)
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šâœ… å…¨å‘˜è¿åŠ¨ä¼šæ£€ç´¢æˆåŠŸï¼Œè¿”å› {len(results)} æ¡")
                    print("====== æ£€ç´¢ç»“æœåŸå§‹æ•°æ® ======")
                    print(json.dumps(results, ensure_ascii=False, indent=2))
                    print("====== æ£€ç´¢ç»“æœç»“æŸ ======")
            elif is_lesson_plan:
                # è¯¾è¯¾ç»ƒæ£€ç´¢
                payload = {
                    "semantic_query": params.get("semantic_query") or "",
                    "count_query": str(params.get("count_query") or ""),
                    "grades_query": str(params.get("grades_query") or ""),
                    "trained_weaknesses": params.get("trained_weaknesses") or "",
                    "top_k": int(params.get("top_k") or 5),
                }
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šè°ƒç”¨æ£€ç´¢ payload={payload}")
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šğŸš€ å¼€å§‹è°ƒç”¨æ£€ç´¢æ¥å£ {SEARCH_BASE_URL}/extended-search/hybrid")
                results = call_hybrid_search(SEARCH_BASE_URL, payload)
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼æ¥å£ï¼šâœ… æ£€ç´¢æ¥å£è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(results)} æ¡")
                    print("====== æ£€ç´¢ç»“æœåŸå§‹æ•°æ® ======")
                    print(json.dumps(results, ensure_ascii=False, indent=2))
                    print("====== æ£€ç´¢ç»“æœç»“æŸ ======")
            else:
                results = []
        except Exception as e:
            if os.getenv('DEBUG_AI','1')=='1':
                print(f"[TEACHER] æµå¼æ¥å£ï¼šæ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨ç©ºç»“æœå…œåº•: {e}")
            results = []

        # æµå¼ç”Ÿæˆæ–¹æ¡ˆ
        def generate():
            try:
                for chunk in generate_plan_stream(results, params, user_text, need_guidance=False):
                    yield chunk
            except Exception as e:
                if os.getenv('DEBUG_AI','1')=='1':
                    print(f"[TEACHER] æµå¼ç”Ÿæˆå¤±è´¥: {e}")
                yield f"\n\nç”Ÿæˆå¤±è´¥: {str(e)}"

        return Response(generate(), mimetype='text/plain; charset=utf-8')

    except Exception as e:
        if os.getenv('DEBUG_AI','1')=='1':
            print(f"[TEACHER] æµå¼ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({'success': False, 'message': f'æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}'}), 500


# ==================== ç­çº§æ•°æ®ç®¡ç†API ====================

@app.route('/api/class_data/upload', methods=['POST'])
def upload_class_data():
    """
    ä¸Šä¼ ç­çº§ä½“æµ‹æ•°æ®å¹¶åˆ†æï¼ˆéæµå¼ï¼‰

    è¯·æ±‚å‚æ•°:
        - file: Excelæ–‡ä»¶
        - class_name: ç­çº§åç§°

    è¿”å›:
        åˆ†æç»“æœ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'message': 'è¯·ä¸Šä¼ æ–‡ä»¶'
            }), 400

        file = request.files['file']
        class_name = request.form.get('class_name', '').strip()

        if not class_name:
            return jsonify({
                'success': False,
                'message': 'è¯·æä¾›ç­çº§åç§°'
            }), 400

        if file.filename == '':
            return jsonify({
                'success': False,
                'message': 'è¯·é€‰æ‹©æ–‡ä»¶'
            }), 400

        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = file.read()

        # åˆ†ææ•°æ®
        result = analyze_uploaded_file(file_content, class_name)

        if result.get('success'):
            return jsonify({
                'success': True,
                'data': result
            })
        else:
            return jsonify({
                'success': False,
                'message': result.get('error', 'åˆ†æå¤±è´¥')
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ†æå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/class_data/upload_stream', methods=['POST'])
def upload_class_data_stream():
    """
    ä¸Šä¼ ç­çº§ä½“æµ‹æ•°æ®å¹¶æµå¼åˆ†æï¼ˆä½¿ç”¨å¤§æ¨¡å‹ï¼‰

    è¯·æ±‚å‚æ•°:
        - file: Excelæ–‡ä»¶
        - class_name: ç­çº§åç§°

    è¿”å›:
        æµå¼åˆ†æè¿‡ç¨‹
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'message': 'è¯·ä¸Šä¼ æ–‡ä»¶'
            }), 400

        file = request.files['file']
        class_name = request.form.get('class_name', '').strip()

        if not class_name:
            return jsonify({
                'success': False,
                'message': 'è¯·æä¾›ç­çº§åç§°'
            }), 400

        if file.filename == '':
            return jsonify({
                'success': False,
                'message': 'è¯·é€‰æ‹©æ–‡ä»¶'
            }), 400

        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = file.read()

        def generate():
            try:
                import pandas as pd
                import io

                # è¯»å–Excelæ–‡ä»¶
                df = pd.read_excel(io.BytesIO(file_content))

                # ä½¿ç”¨å¤§æ¨¡å‹æµå¼åˆ†æ
                profile = None
                for chunk in analyze_with_llm(df, class_name):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆçš„profileç»“æœ
                    if isinstance(chunk, tuple) and len(chunk) == 2 and chunk[0] == "__PROFILE__":
                        # è¿™æ˜¯æœ€ç»ˆçš„profileå­—å…¸
                        profile = chunk[1]
                    elif isinstance(chunk, str):
                        # æµå¼è¾“å‡ºåˆ†æè¿‡ç¨‹
                        yield f"data: {json.dumps({'type': 'progress', 'content': chunk}, ensure_ascii=False)}\n\n"

                # ä¿å­˜é…ç½®
                if profile:
                    update_class_profile(class_name, profile)
                    yield f"data: {json.dumps({'type': 'success', 'profile': profile, 'message': 'âœ… åˆ†æå®Œæˆå¹¶å·²ä¿å­˜ï¼'}, ensure_ascii=False)}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ åˆ†æå¤±è´¥ï¼šæœªè·å–åˆ°åˆ†æç»“æœ'}, ensure_ascii=False)}\n\n"

                yield "data: [DONE]\n\n"

            except Exception as e:
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ åˆ†æå¤±è´¥: {str(e)}'}, ensure_ascii=False)}\n\n"
                yield "data: [DONE]\n\n"

        return Response(generate(), mimetype='text/event-stream')

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ†æå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/class_data/analyze/<path:filename>', methods=['POST'])
def analyze_existing_class_data(filename):
    """
    åˆ†æclass_dataæ–‡ä»¶å¤¹ä¸­å·²æœ‰çš„ä½“æµ‹æ•°æ®æ–‡ä»¶

    å‚æ•°:
        filename: æ–‡ä»¶åï¼ˆä¾‹å¦‚ï¼šä¸€å¹´çº§1ç­.xlsxï¼‰

    è¿”å›:
        åˆ†æç»“æœ
    """
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = Path("class_data") / filename

        if not file_path.exists():
            return jsonify({
                'success': False,
                'message': f'æ–‡ä»¶ä¸å­˜åœ¨: {filename}'
            }), 404

        # åˆ†ææ•°æ®
        result = analyze_class_file(file_path)

        return jsonify({
            'success': True,
            'data': result
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ†æå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/class_data/profiles', methods=['GET'])
def get_class_profiles_api():
    """
    è·å–æ‰€æœ‰ç­çº§é…ç½®

    è¿”å›:
        æ‰€æœ‰ç­çº§é…ç½®
    """
    try:
        profiles = get_all_class_profiles()
        return jsonify({
            "success": True,
            "data": profiles,
            "count": len(profiles)
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"è·å–ç­çº§é…ç½®å¤±è´¥: {str(e)}"
        }), 500


@app.route('/api/class_data/profile/<class_name>', methods=['DELETE'])
def delete_class_profile_api(class_name):
    """
    åˆ é™¤ç­çº§é…ç½®

    å‚æ•°:
        class_name: ç­çº§åç§°

    è¿”å›:
        åˆ é™¤ç»“æœ
    """
    try:
        success = delete_class_profile(class_name)

        if success:
            return jsonify({
                "success": True,
                "message": f"å·²åˆ é™¤ç­çº§é…ç½®: {class_name}"
            })
        else:
            return jsonify({
                "success": False,
                "message": f"ç­çº§é…ç½®ä¸å­˜åœ¨: {class_name}"
            }), 404

    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"åˆ é™¤å¤±è´¥: {str(e)}"
        }), 500


@app.route('/api/class_data/download/<class_name>', methods=['GET'])
def download_class_excel(class_name):
    """
    ä¸‹è½½ç­çº§é…ç½®çš„Excelæ–‡ä»¶

    å‚æ•°:
        class_name: ç­çº§åç§°

    è¿”å›:
        Excelæ–‡ä»¶
    """
    try:
        # è·å–ç­çº§é…ç½®
        profiles = get_all_class_profiles()

        if class_name not in profiles:
            return jsonify({
                "success": False,
                "message": f"ç­çº§é…ç½®ä¸å­˜åœ¨: {class_name}"
            }), 404

        profile = profiles[class_name]

        # åˆ›å»ºExcelæ–‡ä»¶
        output = BytesIO()

        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Sheet 1: ç­çº§åŸºæœ¬ä¿¡æ¯
            basic_info = {
                'ç­çº§åç§°': [class_name],
                'å¹´çº§': [f"{profile.get('grades_query', '')}å¹´çº§"],
                'è–„å¼±é¡¹': [', '.join(profile.get('weaknesses', []))],
                'æè¿°': [profile.get('description', '')]
            }
            df_basic = pd.DataFrame(basic_info)
            df_basic.to_excel(writer, sheet_name='ç­çº§ä¿¡æ¯', index=False)

            # Sheet 2: å­¦ç”Ÿåˆ†ç»„è¯¦æƒ…
            if 'student_groups' in profile and profile['student_groups']:
                all_students = []

                for group_key, group_info in profile['student_groups'].items():
                    weakness_items = ', '.join(group_info.get('weakness_items', []))

                    if 'student_details' in group_info and group_info['student_details']:
                        for student in group_info['student_details']:
                            # ä¼˜å…ˆè·å–å­¦ç”Ÿç¼–å·ï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µ
                            student_id = student.get('å­¦ç”Ÿç¼–å·', '') or student.get('å­¦å·', '') or student.get('ç¼–å·', '')
                            student_name = student.get('å§“å', '')
                            student_index = student.get('åºå·', '')

                            # å¦‚æœæ²¡æœ‰å§“åï¼Œä½¿ç”¨"å­¦ç”ŸX"
                            if not student_name and student_index:
                                student_name = f'å­¦ç”Ÿ{student_index}'

                            student_row = {
                                'åˆ†ç»„': group_key,
                                'è–„å¼±é¡¹ç›®': weakness_items,
                                'å­¦ç”Ÿç¼–å·': str(student_id) if student_id else '',
                                'å§“å': student_name,
                                'æ€§åˆ«': student.get('æ€§åˆ«', '')
                            }
                            all_students.append(student_row)

                if all_students:
                    df_students = pd.DataFrame(all_students)
                    df_students.to_excel(writer, sheet_name='å­¦ç”Ÿåˆ†ç»„', index=False)

            # Sheet 3: å„é¡¹ä½“æµ‹ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'test_stats' in profile and profile['test_stats']:
                stats_data = []
                for item, stats in profile['test_stats'].items():
                    stats_row = {
                        'ä½“æµ‹é¡¹ç›®': item,
                        'ç»´åº¦': stats.get('dimension', ''),
                        'ä¼˜ç§€äººæ•°': stats.get('excellent', 0),
                        'è‰¯å¥½äººæ•°': stats.get('good', 0),
                        'åŠæ ¼äººæ•°': stats.get('pass', 0),
                        'ä¸åŠæ ¼äººæ•°': stats.get('fail', 0)
                    }
                    stats_data.append(stats_row)

                if stats_data:
                    df_stats = pd.DataFrame(stats_data)
                    df_stats.to_excel(writer, sheet_name='ä½“æµ‹ç»Ÿè®¡', index=False)

        output.seek(0)

        # è¿”å›Excelæ–‡ä»¶
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=f'{class_name}_é…ç½®.xlsx'
        )

    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ä¸‹è½½å¤±è´¥: {str(e)}"
        }), 500


@app.route('/api/class_data/download_word/<class_name>', methods=['GET'])
def download_class_word(class_name):
    """
    ä¸‹è½½ç­çº§é…ç½®çš„Wordæ–‡æ¡£ï¼ˆç¾åŒ–ç‰ˆï¼‰

    å‚æ•°:
        class_name: ç­çº§åç§°

    è¿”å›:
        Wordæ–‡ä»¶
    """
    try:
        # è·å–ç­çº§é…ç½®
        profiles = get_all_class_profiles()

        if class_name not in profiles:
            return jsonify({
                "success": False,
                "message": f"ç­çº§é…ç½®ä¸å­˜åœ¨: {class_name}"
            }), 404

        profile = profiles[class_name]

        # åˆ›å»ºWordæ–‡æ¡£
        doc = Document()

        # è®¾ç½®é»˜è®¤å­—ä½“ä¸ºä¸­æ–‡å­—ä½“ï¼ˆè§£å†³ä¹±ç é—®é¢˜ï¼‰
        style = doc.styles['Normal']
        style.font.name = 'å®‹ä½“'
        style._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

        # æ·»åŠ æ ‡é¢˜
        title = doc.add_heading(f'{class_name} ä½“æµ‹æ•°æ®åˆ†ææŠ¥å‘Š', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        if title.runs:
            title.runs[0].font.size = Pt(20)
            title.runs[0].font.name = 'å®‹ä½“'
            title.runs[0]._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

        # æ·»åŠ ç©ºè¡Œ
        doc.add_paragraph()

        # 1. ç­çº§åŸºæœ¬ä¿¡æ¯
        heading1 = doc.add_heading('ä¸€ã€ç­çº§åŸºæœ¬ä¿¡æ¯', 1)
        for run in heading1.runs:
            run.font.name = 'å®‹ä½“'
            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

        # åˆ›å»ºåŸºæœ¬ä¿¡æ¯è¡¨æ ¼
        table1 = doc.add_table(rows=4, cols=2)
        table1.style = 'Light Grid Accent 1'

        # è®¾ç½®è¡¨å¤´
        cells = table1.rows[0].cells
        cells[0].text = 'ç­çº§åç§°'
        cells[1].text = class_name

        cells = table1.rows[1].cells
        cells[0].text = 'å¹´çº§'
        cells[1].text = f"{profile.get('grades_query', '')}å¹´çº§"

        cells = table1.rows[2].cells
        cells[0].text = 'è–„å¼±é¡¹'
        cells[1].text = ', '.join(profile.get('weaknesses', []))

        cells = table1.rows[3].cells
        cells[0].text = 'åˆ†ææè¿°'
        cells[1].text = profile.get('description', '')

        # è®¾ç½®è¡¨æ ¼æ ·å¼ï¼ˆæ·»åŠ å­—ä½“è®¾ç½®ï¼‰
        for row in table1.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    for run in paragraph.runs:
                        run.font.name = 'å®‹ä½“'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
            # ç¬¬ä¸€åˆ—åŠ ç²—
            if row.cells[0].paragraphs and row.cells[0].paragraphs[0].runs:
                row.cells[0].paragraphs[0].runs[0].font.bold = True

        doc.add_paragraph()

        # 2. å­¦ç”Ÿåˆ†ç»„è¯¦æƒ…
        if 'student_groups' in profile and profile['student_groups']:
            heading2 = doc.add_heading('äºŒã€å­¦ç”Ÿåˆ†ç»„è¯¦æƒ…', 1)
            for run in heading2.runs:
                run.font.name = 'å®‹ä½“'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

            for group_key, group_info in profile['student_groups'].items():
                # åˆ†ç»„æ ‡é¢˜
                group_heading = doc.add_heading(f'{group_key}è–„å¼±ç»„ï¼ˆ{group_info["count"]}äººï¼‰', 2)
                for run in group_heading.runs:
                    run.font.name = 'å®‹ä½“'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

                # è–„å¼±é¡¹ç›®
                weakness_items = ', '.join(group_info.get('weakness_items', []))
                p = doc.add_paragraph(f'ä½“æµ‹ä¸åŠæ ¼é¡¹ç›®ï¼š{weakness_items}')
                for run in p.runs:
                    run.font.name = 'å®‹ä½“'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

                # å­¦ç”Ÿåˆ—è¡¨è¡¨æ ¼
                if 'student_details' in group_info and group_info['student_details']:
                    students = group_info['student_details']

                    # åˆ›å»ºè¡¨æ ¼ï¼ˆè¡¨å¤´ + å­¦ç”Ÿè¡Œï¼‰
                    table2 = doc.add_table(rows=len(students) + 1, cols=3)
                    table2.style = 'Light List Accent 1'

                    # è¡¨å¤´
                    header_cells = table2.rows[0].cells
                    header_cells[0].text = 'å­¦ç”Ÿç¼–å·'
                    header_cells[1].text = 'å§“å'
                    header_cells[2].text = 'æ€§åˆ«'

                    # è¡¨å¤´æ ·å¼
                    for cell in header_cells:
                        if cell.paragraphs and cell.paragraphs[0].runs:
                            cell.paragraphs[0].runs[0].font.bold = True
                            cell.paragraphs[0].runs[0].font.size = Pt(11)
                            cell.paragraphs[0].runs[0].font.name = 'å®‹ä½“'
                            cell.paragraphs[0].runs[0]._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

                    # å¡«å……å­¦ç”Ÿæ•°æ®
                    for i, student in enumerate(students, start=1):
                        row_cells = table2.rows[i].cells
                        # ä¼˜å…ˆè·å–å­¦ç”Ÿç¼–å·ï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µ
                        student_id = student.get('å­¦ç”Ÿç¼–å·', '') or student.get('å­¦å·', '') or student.get('ç¼–å·', '')
                        student_name = student.get('å§“å', '')
                        student_index = student.get('åºå·', '')

                        # å¦‚æœæ²¡æœ‰å§“åï¼Œä½¿ç”¨"å­¦ç”ŸX"
                        if not student_name and student_index:
                            student_name = f'å­¦ç”Ÿ{student_index}'

                        row_cells[0].text = str(student_id) if student_id else ''
                        row_cells[1].text = student_name
                        row_cells[2].text = student.get('æ€§åˆ«', '')

                        # è®¾ç½®å­—ä½“
                        for cell in row_cells:
                            for paragraph in cell.paragraphs:
                                for run in paragraph.runs:
                                    run.font.name = 'å®‹ä½“'
                                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

                doc.add_paragraph()

        # 3. ä½“æµ‹ç»Ÿè®¡
        if 'test_stats' in profile and profile['test_stats']:
            heading3 = doc.add_heading('ä¸‰ã€ä½“æµ‹ç»Ÿè®¡', 1)
            for run in heading3.runs:
                run.font.name = 'å®‹ä½“'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

            stats = profile['test_stats']

            # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
            table3 = doc.add_table(rows=len(stats) + 1, cols=6)
            table3.style = 'Light Grid Accent 1'

            # è¡¨å¤´
            header_cells = table3.rows[0].cells
            headers = ['ä½“æµ‹é¡¹ç›®', 'ç»´åº¦', 'ä¼˜ç§€äººæ•°', 'è‰¯å¥½äººæ•°', 'åŠæ ¼äººæ•°', 'ä¸åŠæ ¼äººæ•°']
            for i, header in enumerate(headers):
                header_cells[i].text = header
                if header_cells[i].paragraphs and header_cells[i].paragraphs[0].runs:
                    header_cells[i].paragraphs[0].runs[0].font.bold = True
                    header_cells[i].paragraphs[0].runs[0].font.name = 'å®‹ä½“'
                    header_cells[i].paragraphs[0].runs[0]._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

            # å¡«å……æ•°æ®
            for i, (item, stat) in enumerate(stats.items(), start=1):
                row_cells = table3.rows[i].cells
                row_cells[0].text = item
                row_cells[1].text = stat.get('dimension', '')
                row_cells[2].text = str(stat.get('excellent', 0))
                row_cells[3].text = str(stat.get('good', 0))
                row_cells[4].text = str(stat.get('pass', 0))
                row_cells[5].text = str(stat.get('fail', 0))

                # è®¾ç½®å­—ä½“
                for cell in row_cells:
                    for paragraph in cell.paragraphs:
                        for run in paragraph.runs:
                            run.font.name = 'å®‹ä½“'
                            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

        # ä¿å­˜åˆ°BytesIO
        output = BytesIO()
        doc.save(output)
        output.seek(0)

        # è¿”å›Wordæ–‡ä»¶
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            as_attachment=True,
            download_name=f'{class_name}_é…ç½®.docx'
        )

    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ä¸‹è½½å¤±è´¥: {str(e)}"
        }), 500


@app.route('/api/class_data/batch_analyze', methods=['POST'])
def batch_analyze_class_data():
    """
    æ‰¹é‡åˆ†æclass_dataæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ä½“æµ‹æ•°æ®

    è¯·æ±‚å‚æ•°:
        - max_count: æœ€å¤šåˆ†æå¤šå°‘ä¸ªç­çº§ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        æ‰¹é‡åˆ†æç»“æœ
    """
    try:
        data = request.get_json() or {}
        max_count = data.get('max_count', None)

        # è·å–class_dataæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶
        class_data_dir = Path("class_data")
        if not class_data_dir.exists():
            return jsonify({
                'success': False,
                'message': 'class_dataæ–‡ä»¶å¤¹ä¸å­˜åœ¨'
            }), 404

        excel_files = list(class_data_dir.glob("*.xlsx")) + list(class_data_dir.glob("*.xls"))

        if max_count:
            excel_files = excel_files[:max_count]

        results = []
        for file_path in excel_files:
            try:
                result = analyze_class_file(file_path)
                results.append({
                    'class_name': file_path.stem,
                    'success': True,
                    'data': result
                })
            except Exception as e:
                results.append({
                    'class_name': file_path.stem,
                    'success': False,
                    'error': str(e)
                })

        return jsonify({
            'success': True,
            'total': len(excel_files),
            'results': results
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}'
        }), 500


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

if __name__ == '__main__':
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹Webåº”ç”¨')
    parser.add_argument('--host', '-H', type=str, default=None,
                        help='ç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0ï¼Œå…è®¸æ‰€æœ‰IPè®¿é—®)')
    parser.add_argument('--port', '-p', type=int, default=None,
                        help='ç«¯å£å· (é»˜è®¤: 5000)')
    parser.add_argument('--debug', action='store_true',
                        help='å¼€å¯è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--no-debug', dest='debug', action='store_false',
                        help='å…³é—­è°ƒè¯•æ¨¡å¼')
    parser.set_defaults(debug=None)  # é»˜è®¤ä¸è®¾ç½®ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
    
    args = parser.parse_args()
    
    # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
    host = args.host if args.host is not None else os.getenv('HOST', '0.0.0.0')
    port = args.port if args.port is not None else int(os.getenv('PORT', 5000))
    
    # è°ƒè¯•æ¨¡å¼ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
    if args.debug is not None:
        debug = args.debug
    else:
        debug_env = os.getenv('DEBUG', 'True')
        debug = debug_env.lower() == 'true'

    local_ip = get_local_ip()

    print("=" * 60)
    print("æ•™å¸ˆç«¯AIå¤‡è¯¾åŠ©æ‰‹ï¼ˆæ•´åˆç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    print(f"ç›‘å¬åœ°å€: {host}:{port}")
    print(f"æœ¬åœ°è®¿é—®: http://127.0.0.1:{port}")
    print(f"å±€åŸŸç½‘è®¿é—®: http://{local_ip}:{port}")
    print(f"è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if debug else 'å…³é—­'}")
    print("=" * 60)
    print("\nå¯ç”¨é¡µé¢:")
    print(f"  - æ•™å¸ˆç«¯å¤‡è¯¾åŠ©æ‰‹: http://127.0.0.1:{port}/teacher")
    print(f"  - ç­çº§æ•°æ®ç®¡ç†: http://127.0.0.1:{port}/class_data_manager")
    print("=" * 60)

    app.run(
        host=host,
        port=port,
        debug=debug
    )

