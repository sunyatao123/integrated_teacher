#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import os
import re
import logging
from logging.handlers import RotatingFileHandler
from typing import Dict, List, Tuple, Any
from pathlib import Path

import requests
from ai_model_optimized import OptimizedAIModel

# é…ç½®æ—¥å¿—
def setup_logger():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºlogsç›®å½•
    log_dir = Path(__file__).parent / "logs"
    log_dir.mkdir(exist_ok=True)

    # åˆ›å»ºlogger
    logger = logging.getLogger("teacher_planner")
    logger.setLevel(logging.DEBUG if os.getenv('DEBUG_AI', '1') == '1' else logging.INFO)

    # é¿å…é‡å¤æ·»åŠ handler
    if logger.handlers:
        return logger

    # åˆ›å»ºæ–‡ä»¶handlerï¼ˆå¸¦è½®è½¬ï¼‰
    log_file = log_dir / "teacher_planner.log"
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)

    # åˆ›å»ºæ§åˆ¶å°handlerï¼ˆå¯é€‰ï¼Œç”¨äºå¼€å‘è°ƒè¯•ï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    # è®¾ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    # æ·»åŠ handler
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

# åˆå§‹åŒ–logger
logger = setup_logger()

# æç¤ºè¯æ¨¡æ¿åŠ è½½å‡½æ•°
def load_prompt_template(template_name: str) -> str:
    """ä»promptsæ–‡ä»¶å¤¹åŠ è½½æç¤ºè¯æ¨¡æ¿"""
    template_path = Path(__file__).parent / "prompts" / f"{template_name}.txt"
    try:
        with open(template_path, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        logger.warning(f"æç¤ºè¯æ¨¡æ¿ {template_name}.txt æœªæ‰¾åˆ°")
        return ""

# åŠ è½½ç­çº§é…ç½®
def load_class_profiles() -> Dict[str, Any]:
    """ä»promptsæ–‡ä»¶å¤¹åŠ è½½ç­çº§é…ç½®"""
    profiles_path = Path(__file__).parent / "prompts" / "class_profiles.json"
    try:
        with open(profiles_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        logger.warning("ç­çº§é…ç½®æ–‡ä»¶ class_profiles.json æœªæ‰¾åˆ°")
        return {}

# åŠ è½½ç³»ç»Ÿæç¤ºè¯
TEACHER_SYSTEM_PROMPT = load_prompt_template("teacher_system_prompt")

def _normalize_class_name(text: str) -> str:
    """
    è§„èŒƒåŒ–ç­çº§åç§°ï¼Œå°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
    ä¾‹å¦‚ï¼š"ä¸‰å¹´çº§äº”ç­" -> "ä¸‰å¹´çº§5ç­"
    """
    # ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—çš„æ˜ å°„
    cn_num_map = {
        'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
        'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10'
    }

    result = text
    for cn, num in cn_num_map.items():
        result = result.replace(cn, num)

    return result


def detect_class_and_fill_params(user_text: str, intent: str = "lesson_plan") -> Tuple[bool, Dict[str, Any]]:
    """
    æ£€æµ‹ç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«ç­çº§åç§°ï¼Œå¦‚æœåŒ…å«åˆ™è‡ªåŠ¨å¡«å……å‚æ•°

    å‚æ•°ï¼š
        user_text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        intent: æ„å›¾ç±»å‹ï¼ˆç›®å‰åªæ”¯æŒ lesson_planï¼‰

    è¿”å›ï¼š
        (æ˜¯å¦æ£€æµ‹åˆ°ç­çº§, é¢„å¡«å……çš„å‚æ•°å­—å…¸)

    ç¤ºä¾‹ï¼š
        ç”¨æˆ·è¾“å…¥ï¼š"ä¸€å¹´çº§ä¸€ç­çš„è¯¾è¯¾ç»ƒ"
        è¿”å›ï¼š(True, {"grades_query": "1", "trained_weaknesses": "é€Ÿåº¦", "count_query": "", ...})
    """
    # åªæœ‰è¯¾è¯¾ç»ƒæ„å›¾æ‰æ”¯æŒç­çº§æ£€æµ‹
    if intent != "lesson_plan":
        return False, {}

    # åŠ è½½ç­çº§é…ç½®
    class_profiles = load_class_profiles()

    # å¦‚æœé…ç½®æ–‡ä»¶ä¸ºç©ºï¼Œç›´æ¥è¿”å›
    if not class_profiles:
        return False, {}

    # è§„èŒƒåŒ–ç”¨æˆ·è¾“å…¥ï¼ˆå°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—ï¼‰
    normalized_user_text = _normalize_class_name(user_text)

    # ã€æ”¹è¿›ã€‘ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…é€»è¾‘
    # æŒ‰ç­çº§åç§°é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œä¼˜å…ˆåŒ¹é…æ›´é•¿çš„ç­çº§åç§°ï¼ˆé¿å…"ä¸€å¹´çº§ä¸€ç­"åŒ¹é…åˆ°"ä¸€å¹´çº§"ï¼‰
    sorted_classes = sorted(class_profiles.items(), key=lambda x: len(x[0]), reverse=True)

    # æ£€æµ‹ç”¨æˆ·è¾“å…¥ä¸­æ˜¯å¦åŒ…å«ç­çº§åç§°ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
    for class_name, class_info in sorted_classes:
        # åŒæ—¶è§„èŒƒåŒ–ç­çº§åç§°ï¼Œç¡®ä¿åŒ¹é…ä¸€è‡´æ€§
        normalized_class_name = _normalize_class_name(class_name)
        if normalized_class_name in normalized_user_text:
            # ã€æ–°å¢ã€‘éªŒè¯åŒ¹é…çš„æœ‰æ•ˆæ€§ï¼šç¡®ä¿ä¸æ˜¯éƒ¨åˆ†åŒ¹é…
            # ä¾‹å¦‚ï¼š"ä¸€å¹´çº§ä¸€ç­" ä¸åº”è¯¥åŒ¹é… "ä¸€å¹´çº§ä¸‰ç­"
            # é€šè¿‡æ£€æŸ¥ç­çº§åç§°å‰åçš„å­—ç¬¦æ¥éªŒè¯
            idx = normalized_user_text.find(normalized_class_name)
            if idx != -1:
                # æ£€æŸ¥å‰åå­—ç¬¦ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„ç­çº§åç§°
                before_char = normalized_user_text[idx - 1] if idx > 0 else " "
                after_char = normalized_user_text[idx + len(normalized_class_name)] if idx + len(normalized_class_name) < len(normalized_user_text) else " "

                # ã€ä¿®å¤ã€‘æ”¹è¿›åŒ¹é…é€»è¾‘ï¼š
                # 1. å¦‚æœç­çº§åç§°æœ¬èº«åŒ…å«"ç­"ï¼ˆå¦‚"ä¸€å¹´çº§ä¸€ç­"ï¼‰ï¼Œåé¢ä¸åº”è¯¥å†æœ‰æ•°å­—æˆ–"ç­"
                # 2. å¦‚æœç­çº§åç§°ä¸åŒ…å«"ç­"ï¼ˆå¦‚"kkk"ï¼‰ï¼Œåé¢å¯ä»¥æœ‰"ç­"å­—ï¼ˆå¦‚"kkkç­çº§"ï¼‰
                # 3. å‰é¢ä¸åº”è¯¥æœ‰æ•°å­—ï¼ˆé¿å…"1ä¸€å¹´çº§ä¸€ç­"è¿™ç§æƒ…å†µï¼‰
                is_valid_match = True

                # å‰é¢ä¸åº”è¯¥æœ‰æ•°å­—
                if before_char.isdigit():
                    is_valid_match = False

                # å¦‚æœç­çº§åç§°åŒ…å«"ç­"ï¼Œåé¢ä¸åº”è¯¥å†æœ‰æ•°å­—æˆ–"ç­"
                if "ç­" in normalized_class_name and (after_char.isdigit() or after_char == "ç­"):
                    is_valid_match = False

                # å¦‚æœç­çº§åç§°ä¸åŒ…å«"ç­"ï¼Œåé¢ä¸åº”è¯¥æœ‰æ•°å­—ï¼ˆä½†å¯ä»¥æœ‰"ç­"ï¼‰
                if "ç­" not in normalized_class_name and after_char.isdigit():
                    is_valid_match = False

                if is_valid_match:
                    # æ‰¾åˆ°åŒ¹é…çš„ç­çº§ï¼Œè¿”å›é¢„å¡«å……çš„å‚æ•°
                    params = {
                        "semantic_query": class_info.get("semantic_query", ""),
                        "count_query": class_info.get("count_query", ""),
                        "grades_query": class_info.get("grades_query", ""),
                        "trained_weaknesses": class_info.get("trained_weaknesses", ""),
                        "top_k": 10,
                        "detected_class_name": class_name  # ã€æ–°å¢ã€‘è®°å½•æ£€æµ‹åˆ°çš„ç­çº§åç§°
                    }
                    logger.info(f"[ç­çº§æ£€æµ‹] è¯†åˆ«åˆ°ç­çº§: {class_name}")
                    logger.info(f"[ç­çº§æ£€æµ‹] è‡ªåŠ¨å¡«å……å‚æ•°: {json.dumps(params, ensure_ascii=False)}")
                    return True, params

    # æ²¡æœ‰æ£€æµ‹åˆ°ç­çº§
    logger.info("[ç­çº§æ£€æµ‹] æœªè¯†åˆ«åˆ°é…ç½®æ–‡ä»¶ä¸­çš„ç­çº§")
    return False, {}

def detect_intent_llm(user_text: str, conversation_history: List[Dict[str, str]] = None, timeout: float = 15.0) -> str:
    """
    ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯æƒ³è¿›è¡Œï¼š
    - sports_meeting: å…¨å‘˜è¿åŠ¨ä¼šæ–¹æ¡ˆè®¾è®¡
    - lesson_plan: è¯¾è¯¾ç»ƒæ–¹æ¡ˆè®¾è®¡
    - chat: é—²èŠæˆ–å…¶ä»–
    
    å‚æ•°ï¼š
        user_text: å½“å‰ç”¨æˆ·è¾“å…¥
        conversation_history: å¯¹è¯å†å²è®°å½•
    è¿”å›ï¼š
        "sports_meeting" | "lesson_plan" | "chat"
    """
    model = OptimizedAIModel()
    system = load_prompt_template("intent_recognition")
    
    # æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
    history_text = ""
    if conversation_history:
        recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history
        history_lines = []
        for msg in recent_history:
            role = msg.get("role", "")
            content = msg.get("content", "")
            if role == "user":
                history_lines.append(f"ç”¨æˆ·ï¼š{content}")
            elif role == "assistant":
                history_lines.append(f"åŠ©æ‰‹ï¼š{content}")
        if history_lines:
            history_text = "\n".join(history_lines)
    
    user = f"""
å¯¹è¯å†å²ï¼ˆæœ€è¿‘6è½®ï¼‰ï¼š
{history_text if history_text else "ï¼ˆæ— å†å²è®°å½•ï¼‰"}

å½“å‰ç”¨æˆ·è¾“å…¥ï¼š{user_text}

è¯·åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ï¼Œåªè¾“å‡ºJSONã€‚
""".strip()
    
    resp = model.client.chat.completions.create(
        model=model.model,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
        max_tokens=100,
        temperature=0.1,
    )
    content = resp.choices[0].message.content.strip()
    
    # JSONæˆªå–
    start = content.find("{")
    end = content.rfind("}")
    if start != -1 and end != -1 and end > start:
        try:
            parsed = json.loads(content[start : end + 1])
            intent = parsed.get("intent", "chat")
            if intent in ("sports_meeting", "lesson_plan", "chat"):
                return intent
        except Exception:
            pass
    return "chat"


def collect_entities_llm(
    user_text: str, conversation_history: List[Dict[str, str]] = None, timeout: float = 15.0
) -> Tuple[Dict[str, Any], List[str]]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œå®ä½“æŠ½å–ï¼Œä»ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯å†å²ä¸­æå–å‚æ•°

    è¿”å›ï¼š(æå–çš„å‚æ•°å­—å…¸, ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨)
    """
    # ã€æ–°å¢ã€‘ä¼˜å…ˆæ£€æµ‹ç­çº§åœºæ™¯ï¼Œå¦‚æœæ£€æµ‹åˆ°ç­çº§ï¼Œç›´æ¥è¿”å›é¢„å¡«å……çš„å‚æ•°
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ˜¯lesson_planæ„å›¾ï¼Œå› ä¸ºåªæœ‰è¯¾è¯¾ç»ƒæ‰æ”¯æŒç­çº§æ£€æµ‹
    is_class, class_params = detect_class_and_fill_params(user_text, intent="lesson_plan")
    if is_class:
        # æ£€æµ‹åˆ°ç­çº§ï¼Œç›´æ¥è¿”å›é¢„å¡«å……çš„å‚æ•°ï¼Œmissing=[]
        return class_params, []

    model = OptimizedAIModel()
    system = load_prompt_template("param_extraction_system")
    
    # æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆè‡³å°‘3è½®ï¼Œæœ€å¤š6è½®ï¼‰
    history_text = ""
    if conversation_history:
        recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history
        history_lines = []
        for msg in recent_history:
            role = msg.get("role", "")
            content = msg.get("content", "")
            if role == "user":
                history_lines.append(f"ç”¨æˆ·ï¼š{content}")
            elif role == "assistant":
                history_lines.append(f"åŠ©æ‰‹ï¼š{content}")
        if history_lines:
            history_text = "\n".join(history_lines)
    
    # åŠ è½½ç­çº§é…ç½®å¹¶ç”Ÿæˆç­çº§é…ç½®æ–‡æœ¬
    class_profiles = load_class_profiles()
    class_profiles_text = ""
    if class_profiles:
        class_profiles_text = "å¦‚æœç”¨æˆ·æåˆ°ä»¥ä¸‹ç­çº§ï¼Œç»“åˆç­çº§ä½“æµ‹æ•°æ®æå–trained_weaknessesï¼š\n"
        for class_name, profile in class_profiles.items():
            weaknesses = profile.get("trained_weaknesses", "")
            description = profile.get("description", "")
            class_profiles_text += f"## {class_name}æ ¸å¿ƒè–„å¼±ç»´åº¦ï¼š{weaknesses}\n"
            if "weakness_details" in profile:
                for weakness, detail in profile["weakness_details"].items():
                    class_profiles_text += f"- {weakness}ï¼š{detail}\n"
            class_profiles_text += "\n"
    
    # åŠ è½½å‚æ•°æå–ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
    user_template = load_prompt_template("param_extraction_user")
    user = user_template.format(
        history_text=history_text if history_text else "ï¼ˆæ— å†å²è®°å½•ï¼‰",
        user_text=user_text,
        class_profiles_text=class_profiles_text if class_profiles_text else "ï¼ˆæ— ç­çº§é…ç½®ä¿¡æ¯ï¼‰"
    )

    resp = model.client.chat.completions.create(
        model=model.model,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
        max_tokens=400,
        temperature=0.2,
    )
    content = resp.choices[0].message.content.strip()
    # JSONæˆªå–
    start = content.find("{")
    end = content.rfind("}")
    parsed: Dict[str, Any] = {}
    if start != -1 and end != -1 and end > start:
        try:
            parsed = json.loads(content[start : end + 1])
        except Exception:
            parsed = {}
    out = {
        "semantic_query": parsed.get("semantic_query") or None,
        "count_query": str(parsed.get("count_query")) if parsed.get("count_query") not in (None, "") else None,
        "grades_query": str(parsed.get("grades_query")) if parsed.get("grades_query") not in (None, "") else None,
        "trained_weaknesses": parsed.get("trained_weaknesses") or None,
        "top_k": int(parsed.get("top_k") or 5),
    }
    missing: List[str] = []
    for key in ["semantic_query", "count_query", "grades_query", "trained_weaknesses"]:
        if not out.get(key):
            missing.append(key)
    return out, missing


def _post_json(url: str, payload: Dict[str, Any], timeout: float = 8.0) -> List[Dict[str, Any]]:
    # è®°å½•è¯·æ±‚ä¿¡æ¯
    if os.getenv('DEBUG_AI','1')=='1':
        logger.info(f"[TEACHER] ğŸš€ æ£€ç´¢æ¥å£è¯·æ±‚")
        logger.info(f"   URL: {url}")
        logger.info(f"   Timeout: {timeout}ç§’")
        logger.info(f"   Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")

    resp = requests.post(url, json=payload, timeout=timeout)

    # è®°å½•å“åº”ä¿¡æ¯
    if os.getenv('DEBUG_AI','1')=='1':
        logger.info(f"[TEACHER] âœ… æ£€ç´¢æ¥å£å“åº”: status_code={resp.status_code}")

    if resp.status_code != 200:
        # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        try:
            error_detail = resp.text
            if os.getenv('DEBUG_AI','1')=='1':
                logger.error(f"[TEACHER] æ£€ç´¢æ¥å£é”™è¯¯è¯¦æƒ…: status_code={resp.status_code}, response={error_detail}")
        except:
            pass
    resp.raise_for_status()
    data = resp.json()

    # è®°å½•è¿”å›ç»“æœæ•°é‡
    if isinstance(data, dict) and "results" in data:
        results = data["results"]
        if os.getenv('DEBUG_AI','1')=='1':
            logger.info(f"[TEACHER] ğŸ“Š æ£€ç´¢è¿”å› {len(results)} æ¡ç»“æœ")
        return results
    if isinstance(data, list):
        if os.getenv('DEBUG_AI','1')=='1':
            logger.info(f"[TEACHER] ğŸ“Š æ£€ç´¢è¿”å› {len(data)} æ¡ç»“æœ")
        return data

    if os.getenv('DEBUG_AI','1')=='1':
        logger.warning(f"[TEACHER] âš ï¸ æ£€ç´¢è¿”å›ç©ºç»“æœ")
    return []


def call_hybrid_search(base_url, payload, timeout=8.0):
    url = base_url + "/extended-search/hybrid"
    return _post_json(url, payload, timeout)


def call_sports_meeting_search(base_url, payload, timeout=8.0):
    url = base_url + "/search/hybrid"
    return _post_json(url, payload, timeout)


def build_plan_messages(
    results: List[Dict[str, Any]],
    params: Dict[str, Any],
    user_text: str,
    need_guidance: bool = False,
) -> List[Dict[str, str]]:
    """
    æ„é€ ç”¨äºç”Ÿæˆå¤‡è¯¾æ–¹æ¡ˆçš„messagesï¼Œä¾›æµå¼ä¸éæµå¼å¤ç”¨ã€‚

    å‚æ•°ï¼š
        results: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆå¦‚æœneed_guidance=Trueï¼Œå¯ä»¥ä¸ºç©ºåˆ—è¡¨ï¼‰
        params: å®ä½“æŠ½å–çš„å‚æ•°
        user_text: ç”¨æˆ·åŸå§‹è¾“å…¥
        need_guidance: å¦‚æœä¸ºTrueï¼Œç”Ÿæˆå¼•å¯¼è¯­è€Œä¸æ˜¯æ–¹æ¡ˆ

    è¿”å›ï¼šmessagesåˆ—è¡¨ï¼Œå¯ç›´æ¥ç”¨äºchat.completions.create
    """
    model = OptimizedAIModel()

    # å¦‚æœéœ€è¦å¼•å¯¼ï¼Œç”Ÿæˆå¼•å¯¼æç¤º
    if need_guidance:
        collected_str = json.dumps({
            "semantic_query": params.get("semantic_query") or "",
            "count_query": params.get("count_query") or "",
            "grades_query": params.get("grades_query") or "",
            "trained_weaknesses": params.get("trained_weaknesses") or "",
            "plan_type": params.get("plan_type") or "",
        }, ensure_ascii=False, indent=2)

        # æ ¹æ®æ„å›¾ç±»å‹å’Œå·²æ”¶é›†çš„å®ä½“åˆ¤æ–­ç¼ºå¤±å­—æ®µ
        plan_type = params.get("plan_type")
        is_sports_meeting = plan_type == "sports_meeting"
        is_lesson_plan = plan_type == "lesson_plan"

        # åˆ¤æ–­ç¼ºå¤±å­—æ®µ
        missing_info = []
        if is_sports_meeting:
            # å…¨å‘˜è¿åŠ¨ä¼šï¼šéœ€è¦æ“åœºæ¡ä»¶ã€å¹´çº§ã€äººæ•°ç­‰ä¿¡æ¯
            if not params.get("semantic_query"):
                missing_info.append("æ“åœºæ¡ä»¶ã€è·‘é“æ•°é‡ã€åœºåœ°è§„æ¨¡")
            if not params.get("grades_query"):
                missing_info.append("å‚ä¸å¹´çº§")
            if not params.get("count_query"):
                missing_info.append("å‚ä¸å­¦ç”Ÿäººæ•°")
        elif is_lesson_plan:
            # è¯¾è¯¾ç»ƒï¼šéœ€è¦ç­çº§ï¼ˆgrades_queryï¼‰æˆ–å¼±é¡¹ï¼ˆtrained_weaknessesï¼‰ï¼Œæ»¡è¶³ä»»ä¸€å³å¯
            has_grades = bool(params.get("grades_query"))
            has_weaknesses = bool(params.get("trained_weaknesses"))
            if not has_grades and not has_weaknesses:
                missing_info.append("ç­çº§æˆ–è–„å¼±é¡¹ï¼ˆå¦‚ï¼šé€Ÿåº¦ã€åŠ›é‡ã€æŸ”éŸ§ç­‰ï¼‰")
            elif not has_grades:
                missing_info.append("ç­çº§ä¿¡æ¯")
            elif not has_weaknesses:
                missing_info.append("è–„å¼±é¡¹ï¼ˆå¦‚ï¼šé€Ÿåº¦ã€åŠ›é‡ã€æŸ”éŸ§ç­‰ï¼‰")

        missing_str = "ã€".join(missing_info) if missing_info else "æ— "

        # åŠ è½½å¼•å¯¼è¯­æ¨¡æ¿
        guidance_template = load_prompt_template("guidance_prompt")
        user_prompt = guidance_template.format(
            user_text=user_text,
            collected_info=collected_str,
            plan_type=plan_type or "æœªç¡®å®š",
            missing_info=missing_str
        )
        return [
            {"role": "system", "content": TEACHER_SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ]

    # æ­£å¸¸ç”Ÿæˆæ–¹æ¡ˆ
    # æ±‡æ€»æ£€ç´¢ç»“æœï¼Œæ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
    top_k = int(params.get("top_k") or 5)
    # ä¼˜å…ˆåªå– text å­—æ®µï¼›è‹¥ç¼ºå¤±å†å›é€€åˆ°å…¶ä»–å­—æ®µ
    texts: List[str] = []
    for r in results[: top_k]:
        t = r.get("text")
        if t:
            texts.append(str(t).strip())
            continue
        # å›é€€ï¼šæ‹¼ä¸€ä¸ªç®€è¦æè¿°ï¼Œå°½é‡ä¸ä¸¢å…³é”®ä¿¡æ¯
        title = r.get("title") or r.get("name") or ""
        desc = r.get("description") or r.get("desc") or ""
        media = r.get("image") or r.get("cover") or r.get("thumbnail") or r.get("media_url") or r.get("img") or ""
        fallback = "\n".join(x for x in [title, desc, media] if x) or ""
        if fallback:
            texts.append(fallback)
    results_text = "\n\n".join(texts) if texts else "æ— æ£€ç´¢ç»“æœtextï¼Œéœ€ç”±ä½ ç»“åˆå‚æ•°ç”Ÿæˆé€šç”¨æ–¹æ¡ˆã€‚"

    # ä½¿ç”¨å®ä½“æŠ½å–ç»“æœæœ¬èº«ï¼ˆä¸å†ä½¿ç”¨é»˜è®¤å€¼å…œåº•ï¼Œä»…å¯¹ top_k å…œåº•ï¼‰
    meta = {
        "semantic_query": params.get("semantic_query"),
        "count_query": str(params.get("count_query")),
        "grades_query": str(params.get("grades_query")),
        "trained_weaknesses": params.get("trained_weaknesses"),
        "top_k": int(params.get("top_k") or 10),
    }

    # æ ¹æ®æ„å›¾ç±»å‹ç”Ÿæˆä¸åŒçš„æç¤ºè¯
    plan_type = params.get("plan_type")
    is_sports_meeting = plan_type == "sports_meeting"
    is_lesson_plan = plan_type == "lesson_plan"
    is_chat = plan_type == "chat" or plan_type == ""

    if is_sports_meeting:
        # å…¨å‘˜è¿åŠ¨ä¼šæ–¹æ¡ˆç”Ÿæˆæç¤ºè¯
        template = load_prompt_template("plan_generation_sports_meeting")
        user_prompt = template.format(
            user_text=user_text,
            meta=json.dumps(meta, ensure_ascii=False, indent=2),
            results_text=results_text,
            grades_query=meta.get("grades_query") or "æ ¹æ®ç”¨æˆ·è¾“å…¥ç¡®å®š",
            count_query=meta.get("count_query") or "æ ¹æ®ç”¨æˆ·è¾“å…¥ç¡®å®š",
            semantic_query=meta.get("semantic_query") or "æ ‡å‡†æ“åœº"
        )
    elif is_lesson_plan:
        # è¯¾è¯¾ç»ƒæ–¹æ¡ˆç”Ÿæˆæç¤ºè¯
        # ç”Ÿæˆç­çº§åˆ†ææ–‡æœ¬
        class_analysis_text = ""
        grades_query = params.get("grades_query")
        detected_class_name = params.get("detected_class_name")  # ã€æ–°å¢ã€‘è·å–æ£€æµ‹åˆ°çš„ç­çº§åç§°

        # ã€ä¿®å¤ã€‘ä¼˜å…ˆä½¿ç”¨æ£€æµ‹åˆ°çš„ç­çº§åç§°è¿›è¡Œç²¾ç¡®åŒ¹é…
        if detected_class_name:
            class_profiles = load_class_profiles()
            if detected_class_name in class_profiles:
                profile = class_profiles[detected_class_name]
                weakness_details = profile.get("weakness_details", {})
                student_groups = profile.get("student_groups", {})

                if weakness_details:
                    class_analysis_text = f"   - ç­çº§ï¼š{detected_class_name}\n   - ç­çº§è–„å¼±é¡¹æè¿°ï¼š\n"
                    for weakness, detail in weakness_details.items():
                        class_analysis_text += f"     * {weakness}ï¼š{detail}\n"
                    class_analysis_text += "\n"

                # æ–°å¢ï¼šæ·»åŠ å­¦ç”Ÿåˆ†ç»„ä¿¡æ¯
                if student_groups:
                    class_analysis_text += f"   - {detected_class_name}å­¦ç”Ÿåˆ†ç»„æƒ…å†µï¼š\n"
                    for group_key, group_info in student_groups.items():
                        count = group_info.get("count", 0)
                        weakness_items = group_info.get("weakness_items", [])
                        student_details = group_info.get("student_details", [])

                        # ç”Ÿæˆåˆ†ç»„æè¿°
                        class_analysis_text += f"     * {group_key}è–„å¼±ç»„ï¼š{count}äºº\n"

                        # æ·»åŠ è–„å¼±é¡¹ç›®åˆ—è¡¨
                        if weakness_items:
                            class_analysis_text += f"       è–„å¼±é¡¹ç›®ï¼š{', '.join(weakness_items)}\n"

                        # æ·»åŠ å­¦ç”Ÿåå•ï¼ˆåŒ…å«åºå·å’Œå­¦å·ï¼‰
                        if student_details:
                            class_analysis_text += f"       å­¦ç”Ÿåå•ï¼š\n"
                            for student in student_details:
                                student_num = student.get("åºå·", "")
                                student_id = student.get("å­¦ç”Ÿç¼–å·", "")
                                student_name = student.get("å§“å", "")
                                gender = student.get("æ€§åˆ«", "")

                                # æ„å»ºå­¦ç”Ÿä¿¡æ¯å­—ç¬¦ä¸²
                                if student_name:
                                    student_info = f"{student_name}"
                                else:
                                    student_info = f"å­¦ç”Ÿ{student_num}"

                                class_analysis_text += f"         â€¢ {student_info} [{student_id}]\n"

                        class_analysis_text += "\n"

                    class_analysis_text += "   - **é‡è¦**ï¼šè¯·åœ¨æ–¹æ¡ˆå¼€å¤´å±•ç¤ºä¸Šè¿°å­¦ç”Ÿåˆ†ç»„æƒ…å†µï¼Œå¹¶æ ¹æ®åˆ†ç»„ä¸ºä¸åŒè–„å¼±é¡¹çš„å­¦ç”Ÿæ¨èä¸åŒçš„ç»ƒä¹ ï¼\n"

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­çº§é…ç½®ï¼Œç”Ÿæˆæç¤ºä¿¡æ¯
        if not class_analysis_text and grades_query:
            class_analysis_text = f"   - ç”±äºé…ç½®ä¸­æ²¡æœ‰è¯¥ç­çº§çš„è¯¦ç»†ä¿¡æ¯ï¼Œæœ¬æ–¹æ¡ˆå°†åŸºäº{grades_query}å¹´çº§çš„ä¸€èˆ¬ç‰¹ç‚¹æä¾›é€šç”¨çš„ç»ƒä¹ æ¨èã€‚\n   - **é‡è¦**ï¼šè¯·åœ¨æ–¹æ¡ˆå¼€å¤´å±•ç¤ºè¿™ä¸ªæç¤ºä¿¡æ¯ï¼\n"

        template = load_prompt_template("plan_generation_lesson_plan")
        user_prompt = template.format(
            user_text=user_text,
            meta=json.dumps(meta, ensure_ascii=False, indent=2),
            results_text=results_text,
            class_analysis_text=class_analysis_text
        )
    elif plan_type == "chat" or plan_type == "":
        # é—²èŠæˆ–æœªè¯†åˆ«æ„å›¾ï¼šä»…è¿”å›ç³»ç»Ÿæç¤ºä¸åŸå§‹è¾“å…¥
        messages = [{"role": "system", "content": TEACHER_SYSTEM_PROMPT}]
        if conversation_history := params.get("conversation_history"):
            for msg in conversation_history[-6:]:
                messages.append(msg)
        messages.append({"role": "user", "content": user_text})
        return messages
    else:
        # æœªçŸ¥æ„å›¾ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯
        return [
            {"role": "system", "content": TEACHER_SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ]

    # è¿”å›æ¶ˆæ¯åˆ—è¡¨
    messages = [{"role": "system", "content": TEACHER_SYSTEM_PROMPT}]
    if conversation_history := params.get("conversation_history"):
        for msg in conversation_history[-6:]:
            messages.append(msg)
    messages.append({"role": "user", "content": user_prompt})
    return messages


def generate_plan_stream(
    results: List[Dict[str, Any]],
    params: Dict[str, Any],
    user_text: str,
    need_guidance: bool = False,
):
    """
    æµå¼ç”Ÿæˆå¤‡è¯¾æ–¹æ¡ˆ

    å‚æ•°ï¼š
        results: æ£€ç´¢ç»“æœåˆ—è¡¨
        params: å®ä½“æŠ½å–çš„å‚æ•°
        user_text: ç”¨æˆ·åŸå§‹è¾“å…¥
        need_guidance: å¦‚æœä¸ºTrueï¼Œç”Ÿæˆå¼•å¯¼è¯­è€Œä¸æ˜¯æ–¹æ¡ˆ

    è¿”å›ï¼šç”Ÿæˆå™¨ï¼Œé€å—è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
    """
    model = OptimizedAIModel()
    messages = build_plan_messages(results, params, user_text, need_guidance)

    # è°ƒè¯•ä¿¡æ¯å·²ç§»é™¤ï¼ˆå‰ç«¯å¯è§æ¨¡å‹å›å¤å†…å®¹ï¼‰

    try:
        stream = model.client.chat.completions.create(
            model=model.model,
            messages=messages,
            max_tokens=32768,
            temperature=0.7,
            top_p=0.9,
            stream=True,
        )

        chunk_count = 0
        for event in stream:
            try:
                delta = event.choices[0].delta
                content = getattr(delta, "content", None)
                if content:
                    chunk_count += 1
                    yield content
            except Exception:
                chunk = None
                try:
                    chunk = event["choices"][0]["delta"].get("content")
                except Exception:
                    pass
                if chunk:
                    chunk_count += 1
                    yield chunk
    except Exception as e:
        if os.getenv('DEBUG_AI','1')=='1':
            logger.error(f"[TEACHER] æµå¼ç”Ÿæˆå¤±è´¥: {e}")
        yield f"ç”Ÿæˆå¤±è´¥: {str(e)}"


def generate_plan(
    results: List[Dict[str, Any]],
    params: Dict[str, Any],
    user_text: str,
    need_guidance: bool = False,
) -> str:
    """
    éæµå¼ç”Ÿæˆå¤‡è¯¾æ–¹æ¡ˆ

    å‚æ•°ï¼š
        results: æ£€ç´¢ç»“æœåˆ—è¡¨
        params: å®ä½“æŠ½å–çš„å‚æ•°
        user_text: ç”¨æˆ·åŸå§‹è¾“å…¥
        need_guidance: å¦‚æœä¸ºTrueï¼Œç”Ÿæˆå¼•å¯¼è¯­è€Œä¸æ˜¯æ–¹æ¡ˆ

    è¿”å›ï¼šç”Ÿæˆçš„æ–‡æœ¬
    """
    model = OptimizedAIModel()
    messages = build_plan_messages(results, params, user_text, need_guidance)

    try:
        resp = model.client.chat.completions.create(
            model=model.model,
            messages=messages,
            max_tokens=3000,
            temperature=0.7,
            top_p=0.9,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

