"""
ä½“æµ‹æ•°æ®åˆ†ææ¨¡å—ï¼šè§£æç­çº§ä½“æµ‹æ•°æ®ï¼Œç”Ÿæˆå’Œæ›´æ–°class_profiles.json
æä¾›APIæ¥å£ä¾›Flaskåº”ç”¨è°ƒç”¨
ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ†æ
"""
import pandas as pd
import json
import os
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Generator
import io

# é…ç½®æ—¥å¿—
def setup_analyzer_logger():
    """é…ç½®åˆ†æå™¨æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path(__file__).parent / "logs"
    log_dir.mkdir(exist_ok=True)

    logger = logging.getLogger("analyzer")
    logger.setLevel(logging.DEBUG if os.getenv('DEBUG_AI', '1') == '1' else logging.INFO)

    if logger.handlers:
        return logger

    log_file = log_dir / "analyzer.log"
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)

    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

logger = setup_analyzer_logger()

# å¹´çº§ç¼–å·åˆ°å¹´çº§åç§°çš„æ˜ å°„ï¼ˆå·²åºŸå¼ƒï¼Œæ”¹ä¸ºä»ç­çº§åç§°æå–ï¼‰
GRADE_MAPPING = {
    14: "1", 15: "2", 16: "3", 17: "4", 18: "5",
    19: "6", 20: "7", 21: "8", 22: "9"
}

def extract_grade_from_class_name(class_name: str) -> str:
    """
    ä»ç­çº§åç§°ä¸­æå–å¹´çº§

    æ”¯æŒçš„æ ¼å¼ï¼š
    - "äº”å¹´çº§1ç­" â†’ "5"
    - "ä¸€å¹´çº§1ç­" â†’ "1"
    - "3å¹´çº§2ç­" â†’ "3"
    - "ä¹å¹´çº§1ç­" â†’ "9"

    å‚æ•°:
        class_name: ç­çº§åç§°

    è¿”å›:
        å¹´çº§å­—ç¬¦ä¸²ï¼ˆå¦‚"1"ã€"5"ï¼‰ï¼Œå¦‚æœæå–å¤±è´¥è¿”å›"1"
    """
    import re

    # ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—çš„æ˜ å°„
    cn_num_map = {
        'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
        'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9'
    }

    # å…ˆå°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
    normalized_name = class_name
    for cn, num in cn_num_map.items():
        normalized_name = normalized_name.replace(cn, num)

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¹´çº§
    # åŒ¹é…æ¨¡å¼ï¼šæ•°å­— + "å¹´çº§"
    match = re.search(r'(\d+)å¹´çº§', normalized_name)
    if match:
        grade = match.group(1)
        logger.debug(f"ä»ç­çº§åç§° '{class_name}' ä¸­æå–åˆ°å¹´çº§: {grade}")
        return grade

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
    logger.warning(f"æ— æ³•ä»ç­çº§åç§° '{class_name}' ä¸­æå–å¹´çº§ï¼Œä½¿ç”¨é»˜è®¤å€¼ '1'")
    return "1"

# æ•°æ®åº“è§„å®šçš„6ä¸ªè–„å¼±ç»´åº¦
ALLOWED_WEAKNESSES = ["å½¢æ€", "è€åŠ›", "åŠ›é‡", "æŸ”éŸ§", "é€Ÿåº¦", "æœºèƒ½"]

# ä½“æµ‹é¡¹ç›®åˆ°è–„å¼±ç»´åº¦çš„æ˜ å°„ï¼ˆåªèƒ½ä½¿ç”¨æ•°æ®åº“è§„å®šçš„6ä¸ªç»´åº¦ï¼‰
# æ³¨æ„ï¼šåªå…³æ³¨ä½“æµ‹æ•°æ®ä¸­çš„"ç­‰çº§"åˆ—ï¼Œå¦‚"ä½“é‡ç­‰çº§"ã€"50ç±³è·‘ç­‰çº§"ç­‰
# è¿™é‡Œçš„é¡¹ç›®åç§°å¿…é¡»ä¸Excelä¸­çš„åˆ—åå‰ç¼€å®Œå…¨ä¸€è‡´ï¼ˆå»æ‰"ç­‰çº§"åç¼€ï¼‰
WEAKNESS_MAPPING = {
    "50ç±³è·‘": "é€Ÿåº¦",
    "ä¸€åˆ†é’Ÿä»°å§èµ·å": "åŠ›é‡",
    "å¼•ä½“å‘ä¸Š": "åŠ›é‡",
    "åä½ä½“å‰å±ˆ": "æŸ”éŸ§",
    "ä¸€åˆ†é’Ÿè·³ç»³": "æœºèƒ½",
    "ç«‹å®šè·³è¿œ": "åŠ›é‡",
    "800ç±³è·‘": "è€åŠ›",
    "1000ç±³è·‘": "è€åŠ›",
    "50ç±³Ã—8å¾€è¿”è·‘": "è€åŠ›",
    "è‚ºæ´»é‡": "æœºèƒ½",
    "ä½“é‡": "å½¢æ€"
    # æ³¨æ„ï¼šä¸åŒ…å«"èº«é«˜"å’Œ"BMI"ï¼Œå› ä¸ºæ ‡å‡†ä½“æµ‹æ•°æ®ä¸­æ²¡æœ‰"èº«é«˜ç­‰çº§"å’Œ"BMIç­‰çº§"åˆ—
}

def analyze_student_weaknesses(df: pd.DataFrame) -> Dict[str, List[str]]:
    """
    åˆ†ææ¯ä¸ªå­¦ç”Ÿçš„è–„å¼±é¡¹

    å‚æ•°:
        df: ä½“æµ‹æ•°æ®DataFrame

    è¿”å›:
        å­—å…¸ï¼Œkeyä¸ºå­¦ç”Ÿå§“åï¼Œvalueä¸ºè–„å¼±ç»´åº¦åˆ—è¡¨
    """
    student_weaknesses = {}

    # éå†æ¯ä¸ªå­¦ç”Ÿ
    for idx, row in df.iterrows():
        # ä¼˜å…ˆä½¿ç”¨å­¦ç”Ÿç¼–å·ä½œä¸ºæ ‡è¯†ï¼Œå…¶æ¬¡æ˜¯å§“åï¼Œæœ€åæ‰æ˜¯åºå·
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„åˆ—è·å–å­¦ç”Ÿç¼–å·
        student_id = row.get('å­¦ç”Ÿç¼–å·', '') or row.get('å­¦å·', '') or row.get('ç¼–å·', '')
        student_name = row.get('å§“å', '')

        if student_id:
            student_key = str(student_id)  # ä½¿ç”¨å­¦ç”Ÿç¼–å·ä½œä¸ºä¸»é”®
        elif student_name:
            student_key = student_name  # ä½¿ç”¨å§“åä½œä¸ºä¸»é”®
        else:
            student_key = f'å­¦ç”Ÿ{idx+1}'  # æœ€åæ‰ä½¿ç”¨åºå·

        weaknesses = set()  # ä½¿ç”¨é›†åˆé¿å…é‡å¤

        # æ£€æŸ¥æ¯ä¸ªä½“æµ‹é¡¹ç›®ï¼ˆä½¿ç”¨å…¨å±€WEAKNESS_MAPPINGï¼‰
        for item, dimension in WEAKNESS_MAPPING.items():
            grade_col = f"{item}ç­‰çº§"
            if grade_col in df.columns:
                grade = row.get(grade_col)

                # ä½“é‡ç­‰çº§ä½¿ç”¨ç‰¹æ®Šçš„åˆ†ç±»ç³»ç»Ÿ
                if item == "ä½“é‡":
                    # ä½“é‡ç­‰çº§ï¼šæ­£å¸¸ã€è¶…é‡ã€è‚¥èƒ–ã€ä½ä½“é‡
                    # åªæœ‰"æ­£å¸¸"æ‰ä¸æ˜¯è–„å¼±é¡¹
                    if grade in ["è¶…é‡", "è‚¥èƒ–", "ä½ä½“é‡"]:
                        weaknesses.add(dimension)
                else:
                    # å…¶ä»–é¡¹ç›®ä½¿ç”¨æ ‡å‡†åˆ†ç±»ï¼šä¼˜ç§€ã€è‰¯å¥½ã€åŠæ ¼ã€ä¸åŠæ ¼
                    # å¦‚æœæˆç»©ä¸º"ä¸åŠæ ¼"æˆ–"åŠæ ¼"ï¼Œåˆ™è¯¥ç»´åº¦ä¸ºè–„å¼±é¡¹
                    if grade in ["ä¸åŠæ ¼", "åŠæ ¼"]:
                        weaknesses.add(dimension)

        # åªä¿å­˜æœ‰è–„å¼±é¡¹çš„å­¦ç”Ÿ
        if weaknesses:
            student_weaknesses[student_key] = sorted(list(weaknesses))

    return student_weaknesses


def group_students_by_weakness(student_weaknesses: Dict[str, List[str]], df: pd.DataFrame, class_weaknesses: List[str] = None) -> Dict[str, Dict]:
    """
    æŒ‰ç­çº§è–„å¼±é¡¹å¯¹å­¦ç”Ÿè¿›è¡Œåˆ†ç»„

    æ–°é€»è¾‘ï¼š
    1. åªé’ˆå¯¹ç­çº§çš„2-3ä¸ªè–„å¼±é¡¹è¿›è¡Œåˆ†ç»„
    2. æ¯ä¸ªå­¦ç”Ÿåªçœ‹è¿™2-3ä¸ªç»´åº¦çš„è¡¨ç°
    3. åˆ†ç»„ç»“æœå¦‚ï¼šåŠ›é‡è–„å¼±ç»„ã€é€Ÿåº¦è–„å¼±ç»„ã€åŠ›é‡+é€Ÿåº¦è–„å¼±ç»„ç­‰

    å‚æ•°:
        student_weaknesses: å­¦ç”Ÿè–„å¼±é¡¹å­—å…¸ï¼ˆæ¥è‡ªanalyze_student_weaknessesï¼‰
        df: ä½“æµ‹æ•°æ®DataFrameï¼ˆç”¨äºè·å–å­¦ç”Ÿè¯¦ç»†ä¿¡æ¯å’Œä½“æµ‹é¡¹ç›®ä¿¡æ¯ï¼‰
        class_weaknesses: ç­çº§çš„è–„å¼±é¡¹åˆ—è¡¨ï¼ˆå¦‚["åŠ›é‡", "é€Ÿåº¦"]ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰è–„å¼±é¡¹

    è¿”å›:
        åˆ†ç»„ä¿¡æ¯å­—å…¸ï¼Œkeyä¸ºè–„å¼±é¡¹ç»„åˆï¼ˆå¦‚"åŠ›é‡"ã€"é€Ÿåº¦"ã€"åŠ›é‡+é€Ÿåº¦"ï¼‰ï¼Œvalueä¸ºè¯¥ç»„çš„è¯¦ç»†ä¿¡æ¯
    """
    groups = {}

    # å¦‚æœæ²¡æœ‰æŒ‡å®šç­çº§è–„å¼±é¡¹ï¼Œä½¿ç”¨æ‰€æœ‰è–„å¼±é¡¹ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
    if class_weaknesses is None:
        class_weaknesses = list(set([w for weaknesses in student_weaknesses.values() for w in weaknesses]))

    # éå†æ¯ä¸ªå­¦ç”Ÿï¼Œåªçœ‹ç­çº§è–„å¼±é¡¹çš„è¡¨ç°
    for idx, row in df.iterrows():
        # ä¼˜å…ˆä½¿ç”¨å­¦ç”Ÿç¼–å·ä½œä¸ºæ ‡è¯†ï¼Œå…¶æ¬¡æ˜¯å§“åï¼Œæœ€åæ‰æ˜¯åºå·
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„åˆ—è·å–å­¦ç”Ÿç¼–å·
        student_id = row.get('å­¦ç”Ÿç¼–å·', '') or row.get('å­¦å·', '') or row.get('ç¼–å·', '')
        student_name = row.get('å§“å', '')

        if student_id:
            student_key = str(student_id)  # ä½¿ç”¨å­¦ç”Ÿç¼–å·ä½œä¸ºä¸»é”®
        elif student_name:
            student_key = student_name  # ä½¿ç”¨å§“åä½œä¸ºä¸»é”®
        else:
            student_key = f'å­¦ç”Ÿ{idx+1}'  # æœ€åæ‰ä½¿ç”¨åºå·

        # è·å–å­¦ç”Ÿçš„è¯¦ç»†ä¿¡æ¯
        student_info = {
            "åºå·": idx + 1,  # æ·»åŠ åºå·å­—æ®µï¼Œä»1å¼€å§‹
            "å­¦ç”Ÿç¼–å·": str(student_id) if student_id else '',
            "å§“å": student_name if student_name else ''  # å¦‚æœæ²¡æœ‰å§“åï¼Œä¿æŒä¸ºç©º
        }

        # å°è¯•è·å–å­¦å·ï¼ˆå¦‚æœå­˜åœ¨ï¼Œä¸å­¦ç”Ÿç¼–å·ä¸åŒï¼‰
        if 'å­¦å·' in df.columns:
            student_info["å­¦å·"] = str(row.get('å­¦å·', '')) if row.get('å­¦å·', '') else ''

        # å°è¯•è·å–å…¶ä»–å¯èƒ½çš„å­¦ç”Ÿä¿¡æ¯å­—æ®µ
        for col in ['ç­çº§', 'æ€§åˆ«', 'å¹´é¾„']:
            if col in df.columns:
                val = row.get(col, '')
                student_info[col] = str(val) if val else ''

        # åªæ£€æŸ¥ç­çº§è–„å¼±é¡¹å¯¹åº”çš„ç»´åº¦
        student_class_weaknesses = []
        if student_key in student_weaknesses:
            # è·å–è¯¥å­¦ç”Ÿçš„æ‰€æœ‰è–„å¼±é¡¹
            all_weaknesses = student_weaknesses[student_key]
            # åªä¿ç•™å±äºç­çº§è–„å¼±é¡¹çš„éƒ¨åˆ†
            student_class_weaknesses = [w for w in all_weaknesses if w in class_weaknesses]

        # å¦‚æœè¯¥å­¦ç”Ÿåœ¨ç­çº§è–„å¼±é¡¹ä¸Šæ²¡æœ‰é—®é¢˜ï¼Œè·³è¿‡
        if not student_class_weaknesses:
            continue

        # ç”Ÿæˆåˆ†ç»„keyï¼ˆå¦‚"åŠ›é‡"ã€"åŠ›é‡+é€Ÿåº¦"ï¼‰
        group_key = "+".join(sorted(student_class_weaknesses))

        if group_key not in groups:
            groups[group_key] = {
                "count": 0,
                "students": [],
                "student_details": [],  # æ–°å¢ï¼šå­¦ç”Ÿè¯¦ç»†ä¿¡æ¯åˆ—è¡¨
                "weakness_items": []
            }

        groups[group_key]["count"] += 1
        groups[group_key]["students"].append(student_key)
        groups[group_key]["student_details"].append(student_info)

    # ä¸ºæ¯ä¸ªåˆ†ç»„æ‰¾å‡ºå¯¹åº”çš„ä½“æµ‹é¡¹ç›®ï¼ˆä½¿ç”¨å…¨å±€WEAKNESS_MAPPINGï¼‰
    for group_key, group_info in groups.items():
        weakness_dims = group_key.split("+")
        items = []
        for item, dimension in WEAKNESS_MAPPING.items():
            if dimension in weakness_dims:
                grade_col = f"{item}ç­‰çº§"
                if grade_col in df.columns:
                    items.append(item)
        # å»é‡
        group_info["weakness_items"] = list(set(items))

    # æŒ‰äººæ•°é™åºæ’åº
    sorted_groups = dict(sorted(groups.items(), key=lambda x: x[1]["count"], reverse=True))

    return sorted_groups


def analyze_class_weakness(df: pd.DataFrame, class_name: str) -> Tuple[List[str], Dict[str, str], Dict[str, str]]:
    """
    åˆ†æç­çº§çš„è–„å¼±é¡¹

    è¿”å›: (è–„å¼±é¡¹åˆ—è¡¨, è–„å¼±é¡¹è¯¦ç»†ä¿¡æ¯å­—å…¸, è–„å¼±é¡¹å¯¹åº”çš„ä½“æµ‹é¡¹ç›®å­—å…¸)
    """
    weaknesses = []
    weakness_details = {}
    weakness_items = {}  # è®°å½•æ¯ä¸ªè–„å¼±ç»´åº¦å¯¹åº”çš„ä½“æµ‹é¡¹ç›®

    weakness_scores = {}

    # åˆ†æå„é¡¹ä½“æµ‹æ•°æ®çš„ç­‰çº§åˆ†å¸ƒï¼ˆä½¿ç”¨å…¨å±€WEAKNESS_MAPPINGï¼‰
    for item, dimension in WEAKNESS_MAPPING.items():
        grade_col = f"{item}ç­‰çº§"
        if grade_col not in df.columns:
            continue

        # ç»Ÿè®¡ç­‰çº§åˆ†å¸ƒ
        grade_counts = df[grade_col].value_counts()
        total = len(df[df[grade_col].notna()])

        if total == 0:
            continue

        # ä½“é‡ç­‰çº§ä½¿ç”¨ç‰¹æ®Šçš„åˆ†ç±»ç³»ç»Ÿ
        if item == "ä½“é‡":
            # ä½“é‡ç­‰çº§ï¼šæ­£å¸¸ã€è¶…é‡ã€è‚¥èƒ–ã€ä½ä½“é‡
            normal_count = grade_counts.get("æ­£å¸¸", 0)
            overweight_count = grade_counts.get("è¶…é‡", 0)
            obese_count = grade_counts.get("è‚¥èƒ–", 0)
            underweight_count = grade_counts.get("ä½ä½“é‡", 0)

            normal_rate = normal_count / total * 100
            overweight_rate = overweight_count / total * 100
            obese_rate = obese_count / total * 100
            underweight_rate = underweight_count / total * 100

            # è®¡ç®—è–„å¼±åˆ†æ•°ï¼ˆæ­£å¸¸ç‡è¶Šä½ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šè–„å¼±ï¼‰
            weakness_score = (100 - normal_rate) + obese_rate * 2 + overweight_rate * 1.5 + underweight_rate * 1.5

            # ä¸ºäº†ç»Ÿä¸€æ¥å£ï¼Œå°†ä½“é‡ç­‰çº§æ˜ å°„åˆ°æ ‡å‡†ç­‰çº§
            excellent_count = normal_count
            good_count = 0
            pass_count = overweight_count + underweight_count
            fail_count = obese_count

            excellent_rate = normal_rate
            good_rate = 0
            pass_rate = overweight_rate + underweight_rate
            fail_rate = obese_rate
        else:
            # å…¶ä»–é¡¹ç›®ä½¿ç”¨æ ‡å‡†åˆ†ç±»ï¼šä¼˜ç§€ã€è‰¯å¥½ã€åŠæ ¼ã€ä¸åŠæ ¼
            excellent_count = grade_counts.get("ä¼˜ç§€", 0)
            good_count = grade_counts.get("è‰¯å¥½", 0)
            pass_count = grade_counts.get("åŠæ ¼", 0)
            fail_count = grade_counts.get("ä¸åŠæ ¼", 0)

            excellent_rate = excellent_count / total * 100
            good_rate = good_count / total * 100
            pass_rate = pass_count / total * 100
            fail_rate = fail_count / total * 100

            # è®¡ç®—è–„å¼±åˆ†æ•°ï¼ˆä¼˜ç§€ç‡è¶Šä½ã€åŠæ ¼ç‡è¶Šé«˜ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šè–„å¼±ï¼‰
            weakness_score = (100 - excellent_rate) + pass_rate + fail_rate * 2

        # ä¿®å¤ï¼šå¯¹äºåŒä¸€ç»´åº¦çš„å¤šä¸ªé¡¹ç›®ï¼Œé€‰æ‹©æœ€è–„å¼±çš„é‚£ä¸ª
        if dimension not in weakness_scores or weakness_score > weakness_scores[dimension]["score"]:
            weakness_scores[dimension] = {
                "score": weakness_score,
                "item": item,
                "excellent_rate": excellent_rate,
                "good_rate": good_rate,
                "pass_rate": pass_rate,
                "fail_rate": fail_rate,
                "excellent_count": excellent_count,
                "good_count": good_count,
                "pass_count": pass_count,
                "fail_count": fail_count,
                "total": total
            }

    # æ‰¾å‡ºæœ€è–„å¼±çš„2ä¸ªç»´åº¦
    sorted_weaknesses = sorted(weakness_scores.items(), key=lambda x: x[1]["score"], reverse=True)

    for dimension, stats in sorted_weaknesses[:2]:
        weaknesses.append(dimension)
        weakness_items[dimension] = stats['item']  # è®°å½•å¯¹åº”çš„ä½“æµ‹é¡¹ç›®

        # ç”Ÿæˆè¯¦ç»†æè¿°
        detail = f"ä»ä½“æµ‹æ•°æ®æ¥çœ‹ï¼Œ{dimension}æ˜¯{class_name}çš„è–„å¼±é¡¹ï¼š{stats['item']}"

        if stats['excellent_count'] == 0:
            detail += f"æ— 'ä¼˜ç§€'ç­‰çº§å­¦ç”Ÿï¼Œ"
        else:
            detail += f"ä»…{stats['excellent_count']}äººï¼ˆå æ¯”{stats['excellent_rate']:.1f}%ï¼‰è¾¾åˆ°'ä¼˜ç§€'ï¼Œ"

        if stats['good_count'] > 0:
            detail += f"{stats['good_count']}äººï¼ˆå æ¯”{stats['good_rate']:.1f}%ï¼‰è¾¾åˆ°'è‰¯å¥½'ï¼Œ"

        detail += f"{stats['pass_count']}äººï¼ˆå æ¯”{stats['pass_rate']:.1f}%ï¼‰ä¸º'åŠæ ¼'"

        if stats['fail_count'] > 0:
            detail += f"ï¼Œ{stats['fail_count']}äººï¼ˆå æ¯”{stats['fail_rate']:.1f}%ï¼‰ä¸º'ä¸åŠæ ¼'"

        detail += f"ï¼Œ{dimension}ç´ è´¨æå‡éœ€æ±‚è¿«åˆ‡ã€‚"

        weakness_details[dimension] = detail

    return weaknesses, weakness_details, weakness_items


def analyze_class_file(file_path: Path) -> Dict:
    """åˆ†æå•ä¸ªç­çº§æ–‡ä»¶"""
    df = pd.read_excel(file_path)
    class_name = file_path.stem  # ä¾‹å¦‚ï¼šä¸€å¹´çº§1ç­

    # ä»ç­çº§åç§°ä¸­æå–å¹´çº§ï¼ˆè€Œä¸æ˜¯ä»Excelæ–‡æ¡£å†…éƒ¨çš„"å¹´çº§ç¼–å·"åˆ—ï¼‰
    grade_query = extract_grade_from_class_name(class_name)

    # åˆ†æç­çº§æ•´ä½“è–„å¼±é¡¹
    weaknesses, weakness_details, weakness_test_items = analyze_class_weakness(df, class_name)

    # åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹
    student_weaknesses = analyze_student_weaknesses(df)

    # æŒ‰ç­çº§è–„å¼±é¡¹åˆ†ç»„ï¼ˆåªé’ˆå¯¹ç­çº§çš„2-3ä¸ªè–„å¼±é¡¹ï¼‰
    student_groups = group_students_by_weakness(student_weaknesses, df, class_weaknesses=weaknesses)

    # æ„å»ºç­çº§é…ç½®
    # ç”Ÿæˆç®€æ´çš„æè¿°
    weakness_desc_items = []
    for weakness in weaknesses:
        test_item = weakness_test_items.get(weakness, "")
        if test_item:
            weakness_desc_items.append(f"{weakness}ï¼ˆ{test_item}ï¼‰")
        else:
            weakness_desc_items.append(weakness)

    description = f"{class_name}ä½“è´¨ç›‘æµ‹æ ¸å¿ƒè–„å¼±ç»´åº¦ï¼š" + "ã€".join(weakness_desc_items) if weakness_desc_items else f"{class_name}ä½“è´¨ç›‘æµ‹æ•°æ®"

    profile = {
        "grades_query": grade_query,
        "trained_weaknesses": "ã€".join(weaknesses) if weaknesses else "",
        "count_query": "",
        "semantic_query": "",
        "description": description,
        "weakness_details": weakness_details,
        "student_groups": student_groups  # æ–°å¢ï¼šå­¦ç”Ÿåˆ†ç»„ä¿¡æ¯
    }

    return class_name, profile


def generate_class_profiles(class_data_dir="class_data", output_file="prompts/class_profiles.json", max_classes=10):
    """
    ç”Ÿæˆclass_profiles.jsonæ–‡ä»¶
    
    å‚æ•°:
        class_data_dir: ç­çº§æ•°æ®æ–‡ä»¶å¤¹
        output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        max_classes: æœ€å¤šå¤„ç†å¤šå°‘ä¸ªç­çº§ï¼ˆç”¨äºæµ‹è¯•ï¼Œè®¾ä¸ºNoneå¤„ç†å…¨éƒ¨ï¼‰
    """
    class_data_path = Path(class_data_dir)
    profiles = {}
    
    # è·å–æ‰€æœ‰ç­çº§æ–‡ä»¶
    class_files = sorted(class_data_path.glob("*.xlsx"))
    
    if max_classes:
        class_files = class_files[:max_classes]
    
    logger.info(f"å¼€å§‹åˆ†æ {len(class_files)} ä¸ªç­çº§...")
    
    for idx, file_path in enumerate(class_files, 1):
        try:
            class_name, profile = analyze_class_file(file_path)
            profiles[class_name] = profile
            logger.info(f"[{idx}/{len(class_files)}] åˆ†æå®Œæˆ: {class_name}")
        except Exception as e:
            logger.error(f"[{idx}/{len(class_files)}] åˆ†æå¤±è´¥: {file_path.name}, é”™è¯¯: {e}")
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    output_path = Path(output_file)
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(profiles, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\nç”Ÿæˆå®Œæˆï¼å…±åˆ†æ {len(profiles)} ä¸ªç­çº§ï¼Œä¿å­˜åˆ° {output_file}")
    return profiles


def analyze_with_llm(df: pd.DataFrame, class_name: str) -> Generator[str, None, Dict]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä½“æµ‹æ•°æ®ï¼ˆæµå¼è¾“å‡ºï¼‰

    å‚æ•°:
        df: ä½“æµ‹æ•°æ®DataFrame
        class_name: ç­çº§åç§°

    è¿”å›:
        ç”Ÿæˆå™¨ï¼Œyieldåˆ†æè¿‡ç¨‹ï¼Œæœ€åè¿”å›åˆ†æç»“æœ
    """
    from ai_model_optimized import OptimizedAIModel

    try:
        # ä»ç­çº§åç§°ä¸­æå–å¹´çº§ï¼ˆè€Œä¸æ˜¯ä»Excelæ–‡æ¡£å†…éƒ¨çš„"å¹´çº§ç¼–å·"åˆ—ï¼‰
        grade_query = extract_grade_from_class_name(class_name)

        yield f"ğŸ“Š å¼€å§‹åˆ†æ {class_name} çš„ä½“æµ‹æ•°æ®...\n\n"
        yield f"âœ… æ£€æµ‹åˆ°å¹´çº§ï¼š{grade_query}å¹´çº§\n"
        yield f"âœ… å­¦ç”Ÿäººæ•°ï¼š{len(df)}äºº\n\n"

        # ç»Ÿè®¡å„é¡¹ä½“æµ‹æ•°æ®
        yield "ğŸ“ˆ æ­£åœ¨ç»Ÿè®¡å„é¡¹ä½“æµ‹æŒ‡æ ‡...\n\n"

        # ä½¿ç”¨å…¨å±€WEAKNESS_MAPPINGç»Ÿè®¡æ‰€æœ‰é¡¹ç›®
        stats_text = ""
        for item, dimension in WEAKNESS_MAPPING.items():
            grade_col = f"{item}ç­‰çº§"
            if grade_col in df.columns:
                grade_counts = df[grade_col].value_counts()
                total = len(df[df[grade_col].notna()])
                if total > 0:
                    # ä½“é‡ç­‰çº§ä½¿ç”¨ç‰¹æ®Šçš„åˆ†ç±»ç³»ç»Ÿ
                    if item == "ä½“é‡":
                        stats_text += f"- {item}ï¼ˆ{dimension}ï¼‰ï¼šæ­£å¸¸{grade_counts.get('æ­£å¸¸', 0)}äººï¼Œè¶…é‡{grade_counts.get('è¶…é‡', 0)}äººï¼Œè‚¥èƒ–{grade_counts.get('è‚¥èƒ–', 0)}äººï¼Œä½ä½“é‡{grade_counts.get('ä½ä½“é‡', 0)}äºº\n"
                    else:
                        stats_text += f"- {item}ï¼ˆ{dimension}ï¼‰ï¼šä¼˜ç§€{grade_counts.get('ä¼˜ç§€', 0)}äººï¼Œè‰¯å¥½{grade_counts.get('è‰¯å¥½', 0)}äººï¼ŒåŠæ ¼{grade_counts.get('åŠæ ¼', 0)}äººï¼Œä¸åŠæ ¼{grade_counts.get('ä¸åŠæ ¼', 0)}äºº\n"

        yield stats_text + "\n"

        # è°ƒç”¨å¤§æ¨¡å‹åˆ†æ
        yield "ğŸ¤– æ­£åœ¨ä½¿ç”¨AIåˆ†æè–„å¼±é¡¹...\n\n"

        model = OptimizedAIModel()

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä½“è‚²æ•™å¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹ç­çº§çš„ä½“æµ‹æ•°æ®ï¼Œè¯†åˆ«è–„å¼±é¡¹ã€‚

ç­çº§ï¼š{class_name}
å¹´çº§ï¼š{grade_query}å¹´çº§
å­¦ç”Ÿäººæ•°ï¼š{len(df)}äºº

å„é¡¹ä½“æµ‹æ•°æ®ç»Ÿè®¡ï¼š
{stats_text}

**é‡è¦è§„åˆ™ï¼š**
1. è–„å¼±é¡¹åªèƒ½ä»ä»¥ä¸‹6ä¸ªç»´åº¦ä¸­é€‰æ‹©ï¼šå½¢æ€ã€è€åŠ›ã€åŠ›é‡ã€æŸ”éŸ§ã€é€Ÿåº¦ã€æœºèƒ½
2. è¯·é€‰æ‹©æœ€è–„å¼±çš„1-2ä¸ªç»´åº¦
3. å¯¹æ¯ä¸ªè–„å¼±ç»´åº¦ï¼Œç»™å‡ºè¯¦ç»†çš„åˆ†æè¯´æ˜

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
```json
{{
    "weaknesses": ["ç»´åº¦1", "ç»´åº¦2"],
    "weakness_details": {{
        "ç»´åº¦1": "è¯¦ç»†åˆ†æè¯´æ˜...",
        "ç»´åº¦2": "è¯¦ç»†åˆ†æè¯´æ˜..."
    }}
}}
```"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä½“è‚²æ•™å¸ˆï¼Œæ“…é•¿åˆ†æå­¦ç”Ÿä½“æµ‹æ•°æ®ã€‚"},
            {"role": "user", "content": prompt}
        ]

        try:
            response = model.client.chat.completions.create(
                model=model.model,
                messages=messages,
                max_tokens=1000,
                temperature=0.3
            )
            response_text = response.choices[0].message.content.strip()
            yield f"AIåˆ†æç»“æœï¼š\n{response_text}\n\n"
        except Exception as api_error:
            # è®°å½•è¯¦ç»†çš„APIé”™è¯¯ä¿¡æ¯
            logger.error(f"AIæ¨¡å‹APIè°ƒç”¨å¤±è´¥: {api_error}")
            yield f"âš ï¸ AIåˆ†æå¤±è´¥ï¼ˆ{str(api_error)}ï¼‰ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•åˆ†æ...\n\n"
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•åˆ†æ
            weaknesses, weakness_details, _ = analyze_class_weakness(df, class_name)
            weaknesses = [w for w in weaknesses if w in ALLOWED_WEAKNESSES][:2]

            yield f"âœ… è¯†åˆ«åˆ°è–„å¼±é¡¹ï¼š{', '.join(weaknesses)}\n\n"

            # åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹å’Œåˆ†ç»„
            yield "ğŸ‘¥ æ­£åœ¨åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹...\n"
            student_weaknesses = analyze_student_weaknesses(df)
            yield f"âœ… å·²åˆ†æ {len(student_weaknesses)} åå­¦ç”Ÿçš„è–„å¼±é¡¹\n\n"

            yield f"ğŸ“Š æ­£åœ¨æŒ‰ç­çº§è–„å¼±é¡¹ï¼ˆ{', '.join(weaknesses)}ï¼‰å¯¹å­¦ç”Ÿåˆ†ç»„...\n"
            student_groups = group_students_by_weakness(student_weaknesses, df, class_weaknesses=weaknesses)
            yield f"âœ… å·²ç”Ÿæˆ {len(student_groups)} ä¸ªå­¦ç”Ÿåˆ†ç»„\n\n"

            # æ„å»ºæè¿°
            description = f"{class_name}ä½“è´¨ç›‘æµ‹æ ¸å¿ƒè–„å¼±ç»´åº¦ï¼š" + "ã€".join(weaknesses) if weaknesses else f"{class_name}ä½“è´¨ç›‘æµ‹æ•°æ®"

            profile = {
                "grades_query": grade_query,
                "trained_weaknesses": "ã€".join(weaknesses) if weaknesses else "",
                "count_query": "",
                "semantic_query": "",
                "description": description,
                "weakness_details": weakness_details,
                "student_groups": student_groups
            }

            yield "ğŸ’¾ æ­£åœ¨ä¿å­˜é…ç½®...\n"
            yield ("__PROFILE__", profile)
            return

        # è§£æJSONç»“æœ
        import re
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            analysis_result = json.loads(json_match.group(1))
            weaknesses = analysis_result.get('weaknesses', [])
            weakness_details = analysis_result.get('weakness_details', {})
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•åˆ†æ
            yield "âš ï¸ AIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•åˆ†æ...\n\n"
            weaknesses, weakness_details, _ = analyze_class_weakness(df, class_name)

        # ç¡®ä¿è–„å¼±é¡¹åœ¨å…è®¸çš„èŒƒå›´å†…
        weaknesses = [w for w in weaknesses if w in ALLOWED_WEAKNESSES][:2]

        yield f"âœ… è¯†åˆ«åˆ°è–„å¼±é¡¹ï¼š{', '.join(weaknesses)}\n\n"

        # åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹å’Œåˆ†ç»„
        yield "ğŸ‘¥ æ­£åœ¨åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹...\n"
        student_weaknesses = analyze_student_weaknesses(df)
        yield f"âœ… å·²åˆ†æ {len(student_weaknesses)} åå­¦ç”Ÿçš„è–„å¼±é¡¹\n\n"

        yield f"ğŸ“Š æ­£åœ¨æŒ‰ç­çº§è–„å¼±é¡¹ï¼ˆ{', '.join(weaknesses)}ï¼‰å¯¹å­¦ç”Ÿåˆ†ç»„...\n"
        student_groups = group_students_by_weakness(student_weaknesses, df, class_weaknesses=weaknesses)
        yield f"âœ… å·²ç”Ÿæˆ {len(student_groups)} ä¸ªå­¦ç”Ÿåˆ†ç»„\n\n"

        # æ„å»ºæè¿°
        description = f"{class_name}ä½“è´¨ç›‘æµ‹æ ¸å¿ƒè–„å¼±ç»´åº¦ï¼š" + "ã€".join(weaknesses) if weaknesses else f"{class_name}ä½“è´¨ç›‘æµ‹æ•°æ®"

        profile = {
            "grades_query": grade_query,
            "trained_weaknesses": "ã€".join(weaknesses) if weaknesses else "",
            "count_query": "",
            "semantic_query": "",
            "description": description,
            "weakness_details": weakness_details,
            "student_groups": student_groups
        }

        yield "ğŸ’¾ æ­£åœ¨ä¿å­˜é…ç½®...\n"

        # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥æ ‡è¯†è¿™æ˜¯æœ€ç»ˆç»“æœ
        yield ("__PROFILE__", profile)

    except Exception as e:
        logger.error(f"åˆ†æå¤±è´¥: {e}", exc_info=True)
        yield f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}\n"
        raise e


def analyze_uploaded_file(file_content: bytes, class_name: str, output_file: str = "prompts/class_profiles.json") -> Dict:
    """
    åˆ†æä¸Šä¼ çš„ä½“æµ‹æ•°æ®æ–‡ä»¶

    å‚æ•°:
        file_content: æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        class_name: ç­çº§åç§°
        output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„

    è¿”å›:
        åˆ†æç»“æœå­—å…¸
    """
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(io.BytesIO(file_content))

        # ä»ç­çº§åç§°ä¸­æå–å¹´çº§ï¼ˆè€Œä¸æ˜¯ä»Excelæ–‡æ¡£å†…éƒ¨çš„"å¹´çº§ç¼–å·"åˆ—ï¼‰
        grade_query = extract_grade_from_class_name(class_name)

        # åˆ†æç­çº§æ•´ä½“è–„å¼±é¡¹
        weaknesses, weakness_details, weakness_test_items = analyze_class_weakness(df, class_name)

        # åˆ†æå­¦ç”Ÿä¸ªä½“è–„å¼±é¡¹
        student_weaknesses = analyze_student_weaknesses(df)

        # æŒ‰ç­çº§è–„å¼±é¡¹åˆ†ç»„ï¼ˆåªé’ˆå¯¹ç­çº§çš„2-3ä¸ªè–„å¼±é¡¹ï¼‰
        student_groups = group_students_by_weakness(student_weaknesses, df, class_weaknesses=weaknesses)

        # æ„å»ºç­çº§é…ç½®
        weakness_desc_items = []
        for weakness in weaknesses:
            test_item = weakness_test_items.get(weakness, "")
            if test_item:
                weakness_desc_items.append(f"{weakness}ï¼ˆ{test_item}ï¼‰")
            else:
                weakness_desc_items.append(weakness)

        description = f"{class_name}ä½“è´¨ç›‘æµ‹æ ¸å¿ƒè–„å¼±ç»´åº¦ï¼š" + "ã€".join(weakness_desc_items) if weakness_desc_items else f"{class_name}ä½“è´¨ç›‘æµ‹æ•°æ®"

        profile = {
            "grades_query": grade_query,
            "trained_weaknesses": "ã€".join(weaknesses) if weaknesses else "",
            "count_query": "",
            "semantic_query": "",
            "description": description,
            "weakness_details": weakness_details,
            "student_groups": student_groups  # æ–°å¢ï¼šå­¦ç”Ÿåˆ†ç»„ä¿¡æ¯
        }

        # æ›´æ–°JSONæ–‡ä»¶
        update_class_profile(class_name, profile, output_file)

        return {
            "success": True,
            "class_name": class_name,
            "profile": profile
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


def update_class_profile(class_name: str, profile: Dict, output_file: str = "prompts/class_profiles.json"):
    """
    æ›´æ–°class_profiles.jsonæ–‡ä»¶

    å‚æ•°:
        class_name: ç­çº§åç§°
        profile: ç­çº§é…ç½®
        output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
    """
    output_path = Path(output_file)
    output_path.parent.mkdir(exist_ok=True)

    # è¯»å–ç°æœ‰é…ç½®
    if output_path.exists():
        try:
            with open(output_path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    profiles = json.loads(content)
                else:
                    profiles = {}
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœJSONæ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œåˆå§‹åŒ–ä¸ºç©ºå­—å…¸
            profiles = {}
    else:
        profiles = {}

    # æ›´æ–°é…ç½®
    profiles[class_name] = profile

    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(profiles, f, ensure_ascii=False, indent=2)


def delete_class_profile(class_name: str, output_file: str = "prompts/class_profiles.json") -> bool:
    """
    åˆ é™¤ç­çº§é…ç½®

    å‚æ•°:
        class_name: ç­çº§åç§°
        output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„

    è¿”å›:
        æ˜¯å¦åˆ é™¤æˆåŠŸ
    """
    output_path = Path(output_file)

    if not output_path.exists():
        return False

    try:
        with open(output_path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                profiles = json.loads(content)
            else:
                profiles = {}
    except (json.JSONDecodeError, ValueError):
        # å¦‚æœJSONæ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œè¿”å›False
        return False

    if class_name in profiles:
        del profiles[class_name]

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(profiles, f, ensure_ascii=False, indent=2)

        return True

    return False


def get_all_class_profiles(output_file: str = "prompts/class_profiles.json") -> Dict:
    """
    è·å–æ‰€æœ‰ç­çº§é…ç½®

    å‚æ•°:
        output_file: JSONæ–‡ä»¶è·¯å¾„

    è¿”å›:
        æ‰€æœ‰ç­çº§é…ç½®å­—å…¸
    """
    output_path = Path(output_file)

    if not output_path.exists():
        return {}

    try:
        with open(output_path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                return json.loads(content)
            else:
                return {}
    except (json.JSONDecodeError, ValueError):
        # å¦‚æœJSONæ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œè¿”å›ç©ºå­—å…¸
        return {}


if __name__ == "__main__":
    # æµ‹è¯•ï¼šåˆ†æclass_dataæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ç­çº§
    generate_class_profiles(max_classes=None)

