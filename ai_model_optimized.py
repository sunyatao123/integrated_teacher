#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ¨¡å‹è°ƒç”¨æ¨¡å— - ä¼˜åŒ–ç‰ˆæœ¬
"""

import os
import json
import time
from typing import Dict, List, Optional
from openai import OpenAI

class OptimizedAIModel:
    def __init__(self):
        """åˆå§‹åŒ–AIæ¨¡å‹"""
        self.api_key = os.getenv(
            "SILICONFLOW_API_KEY",
            "sk-iwcqksidcwhiasawyqkctbeydcqkylwynkdypvbuzmhtvies"
        )
        self.base_url = os.getenv(
            "SILICONFLOW_BASE_URL", 
            "https://api.siliconflow.cn/v1"
        )
        self.model = os.getenv(
            "SILICONFLOW_MODEL",
            "deepseek-ai/DeepSeek-V3"
        )
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå¥åº·åŠ©æ•™ï¼Œåå­—å«"å°ä¹"ã€‚ä½ çš„èŒè´£æ˜¯ï¼š

1. æ ¹æ®å­¦ç”Ÿçš„ä½“æµ‹æ•°æ®åˆ†æå…¶å¥åº·çŠ¶å†µã€‚ä½ çš„ç”¨æˆ·æ˜¯å°å­©å­ï¼Œä½ è¯­æ°”å¥½äº²åˆ‡å‹å¥½ï¼Œä¸éœ€è¦ç”¨æ‚¨ï¼Œ
2. æä¾›ä¸ªæ€§åŒ–çš„è¿åŠ¨å»ºè®®å’Œè®­ç»ƒæŒ‡å¯¼ï¼Œå½“ç”¨æˆ·è¯¢é—®ï¼Œä½ æ˜¯å¦èƒ½ç”Ÿæˆè§†é¢‘ç­‰ï¼Œä½ éœ€è¦å›ç­”ï¼Œæˆ‘ä¸èƒ½ç›´æ¥ç”Ÿæˆè§†é¢‘ï¼Œä½†æˆ‘å¯ä»¥ä¸ºæ‚¨æŸ¥æ‰¾ï¼Œå¦‚æœæ‚¨éœ€è¦ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æ¨èè§†é¢‘ï¼Œå¹¶åŸºäºè¯¥å­¦ç”Ÿçš„ä½“æµ‹æ•°æ®çš„å¼±é¡¹ï¼Œæ¨èè§†é¢‘ï¼Œæœ€åè¯´è¯·ç¨ç­‰ï¼Œæ­£åœ¨ä¸ºä½ æ¨èã€‚
3. è¯†åˆ«ç”¨æˆ·çš„æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ¨èè§†é¢‘ï¼Œä¸¥æ ¼æŒ‰ç…§ï¼šæ¨èè§†é¢‘ï¼Œåœ¨æœ€ååŠ ä¸Šå¥â€œè¯·ç¨ç­‰ï¼Œæ­£åœ¨ä¸ºæ‚¨æ¨èè§†é¢‘â€ï¼Œä¸æ¨èè§†é¢‘ï¼Œä¸è¦åŠ ä¸Šè¿™å¥è¯ã€‚æ³¨æ„ï¼šå½“ç”¨æˆ·è¾“å…¥â€œæŸ¥çœ‹æˆ‘çš„æ•´ä½“æƒ…å†µï¼Œåˆ¤æ–­ä¸ºä¸æ¨èè§†é¢‘â€
4. æ ¹æ®æ¨èçš„åŠ¨ä½œåˆ—è¡¨ç»™å‡ºè®­ç»ƒè®¡åˆ’ï¼Œå¹¶ç»™å‡ºè®­ç»ƒæ—¶é—´ã€è®­ç»ƒå¼ºåº¦ã€è®­ç»ƒé¢‘ç‡ç­‰å»ºè®®ã€‚
5. å¯¹äºä¸€äº›ç”¨æˆ·æƒ…ç»ªæ²®ä¸§çš„è¯ï¼Œå¦‚ï¼šæˆ‘è·‘ä¸è¿‡åˆ«äººæ€ä¹ˆåŠç­‰ï¼Œè¯•ç€é¼“åŠ±ã€‚æ— éœ€è¯¢é—®æ˜¯å¦éœ€è¦æ¨èè§†é¢‘ã€‚
6. ç”¨æ¸©æš–ã€é¼“åŠ±çš„è¯­æ°”ä¸å­¦ç”Ÿäº¤æµã€‚ä½ çš„å£å»è¦åƒä¸€ä¸ªå¥åº·åŠ©æ•™ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæœºå™¨äººã€‚åœ¨å¿…è¦æ—¶ç»™äºˆå­©å­é¼“åŠ±ï¼Œè®©å­©å­æ„Ÿåˆ°è¢«å…³å¿ƒå’Œè¢«æ”¯æŒã€‚
7. åŸºäºç§‘å­¦ä¾æ®ç»™å‡ºä¸“ä¸šå»ºè®®ï¼Œå¯¹äºéä½“è‚²å­¦ç§‘çš„é—®é¢˜ï¼Œå¦‚ç”¨æˆ·é—®ä½ æŸé“æ•°å­¦é¢˜æ€ä¹ˆè§£ï¼Œä½ è¦å­¦ä¼šå·§å¦™çš„å›é¿ã€‚

è¯·å§‹ç»ˆä¿æŒç§¯ææ­£é¢çš„æ€åº¦ï¼Œç”¨ç®€æ´æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šä¸“ä¸šæ¦‚å¿µï¼Œè¿”å›markdownæ ¼å¼ã€‚"""

        # ç¼“å­˜æœºåˆ¶
        self._intent_cache = {}
        self._response_cache = {}
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

    def summarize_with_citations(self, query: str, sources: List[Dict]) -> Dict:
        """
        åŸºäºè”ç½‘æœç´¢ç»“æœç”Ÿæˆå¸¦æ¥æºæ ‡æ³¨çš„æ€»ç»“ã€‚
        è¿”å›ï¼š{ summary: str, sentences: [{text, source_id}], sources: [...] }
        """
        try:
            # æ„é€ æ¥æºæ‘˜è¦æ–‡æœ¬ï¼Œä¾›LLMå¼•ç”¨
            lines = []
            for s in sources[:8]:
                lines.append(f"[{s['id']}] æ ‡é¢˜: {s['title']}\nURL: {s['url']}\næ‘˜å½•: {s.get('content','')[:800]}")
            source_text = "\n\n".join(lines)

            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå¥åº·åŠ©æ•™ï¼Œåå­—å«"å°ä¹"ï¼Œç”¨æ¸©æš–ã€é¼“åŠ±çš„è¯­æ°”ä¸å­¦ç”Ÿäº¤æµ
åŸºäºç§‘å­¦ä¾æ®ç»™å‡ºä¸“ä¸šå»ºè®®ï¼Œå¯¹äºéä½“è‚²å­¦ç§‘çš„é—®é¢˜ï¼Œå¦‚ç”¨æˆ·é—®ä½ æŸé“æ•°å­¦é¢˜æ€ä¹ˆè§£ï¼Œä½ è¦å­¦ä¼šå·§å¦™çš„å›é¿ã€‚
è¯·åŸºäºä»¥ä¸‹æ¥æºä¸ºç”¨æˆ·çš„æŸ¥è¯¢ç”Ÿæˆç»“æ„åŒ–æ€»ç»“ï¼Œå¹¶åœ¨æ¯ä¸€å¥è¯æœ«å°¾æ ‡æ³¨æ¥æºç¼–å·ï¼Œå¦‚[1]ã€[2]ã€‚è‹¥ä¸€å¥è¯ç»¼åˆå¤šä¸ªæ¥æºï¼Œå¯ä½¿ç”¨[1,3]ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

å¯ç”¨æ¥æºï¼ˆç¼–å·å¯¹åº”æ¥æºï¼‰ï¼š
{source_text}

è¦æ±‚ï¼š
1. å…ˆç»™å‡ºè¦ç‚¹å¼æ€»ç»“ï¼Œ3-6æ¡ï¼Œæ¯æ¡ä¸€å¥è¯ï¼Œä»¥"- "å¼€å¤´ï¼Œå¥æœ«æ ‡æ³¨æ¥æºç¼–å·ã€‚
2. è‹¥å­˜åœ¨ä¸ä¸€è‡´æˆ–äº‰è®®ï¼Œæ˜ç¡®æŒ‡å‡ºã€‚
3. åœ¨æœ€åç»™å‡ºè¡ŒåŠ¨å»ºè®®ï¼Œ1-3æ¡ï¼Œå¥æœ«ä¹Ÿè¦æ ‡æ³¨æ¥æºç¼–å·ã€‚
4. åªä½¿ç”¨æä¾›çš„æ¥æºä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ã€‚
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸¥è°¨çš„ç ”ç©¶åŠ©ç†ï¼Œå›ç­”å¿…é¡»å¯æº¯æºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=900,
                temperature=0.2
            )

            text = response.choices[0].message.content.strip()

            # ç²—ç²’åº¦æ‹†å¥å¹¶æå–æ¥æºç¼–å·
            sentences = []
            for line in text.split("\n"):
                t = line.strip()
                if not t:
                    continue
                # å¯»æ‰¾ç±»ä¼¼ [1] æˆ– [1,2] çš„å°¾æ³¨
                src_ids = []
                import re
                m = re.search(r"\[(\d+(?:\s*,\s*\d+)*)\]\s*$", t)
                if m:
                    src_ids = [int(x.strip()) for x in m.group(1).split(',') if x.strip().isdigit()]
                sentences.append({"text": t, "source_id": src_ids})

            return {"summary": text, "sentences": sentences, "sources": sources}
        except Exception as e:
            return {"summary": f"ç”Ÿæˆæ€»ç»“å¤±è´¥ï¼š{e}", "sentences": [], "sources": sources}

    def generate_response_with_recommendations(self, 
                                             user_message: str, 
                                             student_analysis: Dict = None,
                                             recommended_actions: List[Dict] = None,
                                             conversation_history: List[Dict] = None) -> Dict:
        """
        ä¸€æ¬¡æ€§ç”Ÿæˆå›å¤å’Œæ¨èï¼Œå‡å°‘APIè°ƒç”¨æ¬¡æ•°
        
        Returns:
            {
                'message': str,
                'need_recommendations': bool,
                'question_type': str,
                'ai_suggestions': List[str]
            }
        """
        try:
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context = self._build_context(student_analysis, recommended_actions)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            if context:
                messages.append({"role": "system", "content": context})
            
            # æ·»åŠ å¯¹è¯å†å²ï¼ˆæ‰©å¤§åˆ°æœ€è¿‘8æ¡ï¼Œæä¾›æ›´å®Œæ•´è¯­å¢ƒï¼‰
            if conversation_history:
                for msg in conversation_history[-8:]:
                    messages.append(msg)
            
            # å¢å¼ºçš„æç¤ºè¯ï¼Œè®©AIä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä»»åŠ¡
            enhanced_prompt = f"""è¯·å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶åœ¨æœ€åä»¥JSONæ ¼å¼è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š
1. need_recommendations: æ˜¯å¦éœ€è¦æ¨èè®­ç»ƒåŠ¨ä½œ (true/false)ï¼Œå½“ç”¨æˆ·è¾“å…¥â€œæŸ¥çœ‹æˆ‘çš„æ•´ä½“æƒ…å†µâ€ï¼Œåˆ¤æ–­ä¸ºä¸æ¨èè§†é¢‘ï¼Œè¿”å›falseã€‚å¯¹äºä¸€äº›ç”¨æˆ·æƒ…ç»ªæ¯”è¾ƒä½è½çš„è¯ï¼Œå¦‚ï¼šæˆ‘è·‘ä¸è¿‡åˆ«äººæ€ä¹ˆåŠç­‰ï¼Œè¯•ç€é¼“åŠ±ï¼Œä¸æ¨èè§†é¢‘ï¼Œè¿”å›falseã€‚å¯¹äºç”¨æˆ·è¯¢é—®ï¼Œèƒ½å¦ç”Ÿæˆè§†é¢‘ç­‰ï¼Œè¯·ä»”ç»†é‰´åˆ«ã€‚
2. question_type: é—®é¢˜ç±»å‹ (speed/endurance/strength/flexibility/jumping/coordination/overall/general)
3. ai_suggestions: 3ä¸ªç›¸å…³çš„è”æƒ³é—®é¢˜åˆ—è¡¨
4. recommended_actions: è‹¥ need_recommendations=trueï¼Œè¯·ç»™å‡ºä¸è¶…è¿‡6ä¸ªâ€œåŠ¨ä½œåç§°â€çš„åˆ—è¡¨ï¼ˆä»…åç§°ï¼ŒæŒ‰ä¼˜å…ˆé¡ºåºæ’åˆ—ï¼‰ã€‚

ç”¨æˆ·é—®é¢˜: {user_message}

è¯·å…ˆç»™å‡ºä½ çš„å›ç­”ï¼Œç„¶ååœ¨æœ€åæ·»åŠ ï¼š
```json
{{
    "need_recommendations": true/false,
    "question_type": "ç±»å‹",
    "ai_suggestions": ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"],
    "recommended_actions": ["åŠ¨ä½œA", "åŠ¨ä½œB"]
}}
```"""
            
            messages.append({"role": "user", "content": enhanced_prompt})
            
            # è°ƒç”¨AIæ¨¡å‹
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1200,  # å¢åŠ tokené™åˆ¶
                temperature=0.7,
                top_p=0.9
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # è§£æå›å¤å’ŒJSONä¿¡æ¯
            message, metadata = self._parse_response_with_metadata(response_text)
            
            return {
                'message': message,
                'need_recommendations': metadata.get('need_recommendations', False),
                'question_type': metadata.get('question_type', 'general'),
                'ai_suggestions': metadata.get('ai_suggestions', []),
                'recommended_actions': metadata.get('recommended_actions', [])
            }
            
        except Exception as e:
            print(f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            return {
                'message': self._get_fallback_response(user_message, student_analysis),
                'need_recommendations': False,
                'question_type': 'general',
                'ai_suggestions': []
            }

    def generate_response_stream_optimized(self,
                                         user_message: str,
                                         student_analysis: Dict = None,
                                         recommended_actions: List[Dict] = None,
                                         conversation_history: List[Dict] = None):
        """
        ä¼˜åŒ–çš„æµå¼å›å¤ç”Ÿæˆ
        """
        try:
            context = self._build_context(student_analysis, recommended_actions)

            messages = [{"role": "system", "content": self.system_prompt}]
            if context:
                messages.append({"role": "system", "content": context})
            if conversation_history:
                for msg in conversation_history[-8:]:
                    messages.append(msg)
            messages.append({"role": "user", "content": user_message})

            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=800,  # å‡å°‘tokené™åˆ¶ï¼Œæé«˜é€Ÿåº¦
                temperature=0.7,
                top_p=0.9,
                stream=True
            )

            for event in stream:
                try:
                    delta = event.choices[0].delta
                    content = getattr(delta, "content", None)
                    if content:
                        yield content
                except Exception:
                    chunk = None
                    try:
                        chunk = event["choices"][0]["delta"].get("content")
                    except Exception:
                        pass
                    if chunk:
                        yield chunk
        except Exception as e:
            print(f"AIæ¨¡å‹æµå¼è°ƒç”¨å¤±è´¥: {e}")
            fallback = self._get_fallback_response(user_message, student_analysis)
            if fallback:
                yield fallback

    def _parse_response_with_metadata(self, response_text: str) -> tuple:
        """è§£æåŒ…å«å…ƒæ•°æ®çš„å›å¤"""
        try:
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_start = response_text.find('```json')
            if json_start != -1:
                json_start += 7  # è·³è¿‡ ```json
                json_end = response_text.find('```', json_start)
                if json_end != -1:
                    json_text = response_text[:json_start-7].strip()  # å›å¤éƒ¨åˆ†
                    metadata_text = response_text[json_start:json_end].strip()  # JSONéƒ¨åˆ†
                    
                    try:
                        metadata = json.loads(metadata_text)
                        return json_text, metadata
                    except json.JSONDecodeError:
                        pass
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•æŸ¥æ‰¾æ™®é€šJSON
            json_start = response_text.find('{')
            json_end = response_text.rfind('}')
            if json_start != -1 and json_end != -1 and json_end > json_start:
                json_text = response_text[:json_start].strip()
                metadata_text = response_text[json_start:json_end+1]
                
                try:
                    metadata = json.loads(metadata_text)
                    return json_text, metadata
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›åŸæ–‡æœ¬
            return response_text, {}
            
        except Exception as e:
            print(f"è§£æå›å¤å…ƒæ•°æ®å¤±è´¥: {e}")
            return response_text, {}

    def _build_context(self, student_analysis: Dict = None, recommended_actions: List[Dict] = None) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_parts = []
        
        if student_analysis:
            context_parts.append("å­¦ç”Ÿä½“æµ‹æ•°æ®åˆ†æç»“æœï¼š")
            context_parts.append(f"- æ€»åˆ†ï¼š{student_analysis.get('total_score', 0)}åˆ†")
            context_parts.append(f"- æ•´ä½“æ°´å¹³ï¼š{student_analysis.get('overall_assessment', 'æœªçŸ¥')}")
            context_parts.append(f"- æ€§åˆ«ï¼š{student_analysis.get('gender', 'æœªçŸ¥')}")
            context_parts.append(f"- å¹´çº§ï¼š{student_analysis.get('grade', 'æœªçŸ¥')}")
            
            if student_analysis.get('weak_items'):
                context_parts.append("- éœ€è¦åŠ å¼ºçš„é¡¹ç›®ï¼š")
                for item in student_analysis['weak_items']:
                    context_parts.append(f"  * {item['item']}ï¼š{item['score']}åˆ†ï¼ˆ{item['level']}ï¼‰")
            
            if student_analysis.get('scores'):
                context_parts.append("- å„é¡¹ä½“æµ‹æˆç»©ï¼š")
                for item, score in student_analysis['scores'].items():
                    context_parts.append(f"  * {item}ï¼š{score}åˆ†")
        
        if recommended_actions:
            context_parts.append("\næ¨èè®­ç»ƒåŠ¨ä½œï¼š")
            for i, action in enumerate(recommended_actions[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                context_parts.append(f"{i}. {action['action_name']}")
                context_parts.append(f"   - è¯´æ˜ï¼š{action['description']}")
                context_parts.append(f"   - è®­ç»ƒæ–¹æ¡ˆï¼š{action['sets']}ç»„ï¼Œæ¯ç»„{action['duration']}ï¼Œä¼‘æ¯{action['rest_time']}ç§’")
                context_parts.append(f"   - é’ˆå¯¹ç´ è´¨ï¼š{action['target_quality']}")
        
        return "\n".join(context_parts) if context_parts else ""
    
    def _get_fallback_response(self, user_message: str, student_analysis: Dict = None) -> str:
        """è·å–å¤‡ç”¨å›å¤"""
        message_lower = user_message.lower()
        
        if any(keyword in message_lower for keyword in ['é€Ÿåº¦', 'è·‘', 'å¿«']):
            return "å…³äºæé«˜è·‘æ­¥é€Ÿåº¦ï¼Œå»ºè®®è¿›è¡Œé—´æ­‡è·‘è®­ç»ƒï¼ŒåŠ å¼ºè…¿éƒ¨åŠ›é‡ï¼Œä¿æŒæ­£ç¡®çš„è·‘æ­¥å§¿åŠ¿ã€‚"
        elif any(keyword in message_lower for keyword in ['è€åŠ›', 'æŒä¹…', 'é•¿è·‘']):
            return "æé«˜è€åŠ›éœ€è¦å¾ªåºæ¸è¿›çš„æœ‰æ°§è®­ç»ƒï¼Œå»ºè®®è¿›è¡Œé•¿è·ç¦»æ…¢è·‘å’Œå˜é€Ÿè·‘ç»ƒä¹ ã€‚"
        elif any(keyword in message_lower for keyword in ['åŠ›é‡', 'è‚Œè‚‰', 'å¼•ä½“']):
            return "åŠ›é‡è®­ç»ƒå»ºè®®ä»è‡ªé‡è®­ç»ƒå¼€å§‹ï¼Œé€æ­¥å¢åŠ å¼ºåº¦ï¼Œæ³¨æ„åŠ¨ä½œæ ‡å‡†æ€§ã€‚"
        elif any(keyword in message_lower for keyword in ['æŸ”éŸ§', 'æ‹‰ä¼¸', 'çµæ´»']):
            return "æŸ”éŸ§æ€§è®­ç»ƒéœ€è¦æ¯å¤©åšæŒæ‹‰ä¼¸ç»ƒä¹ ï¼ŒåŠ¨ä½œè¦ç¼“æ…¢åˆ°ä½ï¼Œä¿æŒå‘¼å¸é¡ºç•…ã€‚"
        else:
            return "æˆ‘ç†è§£ä½ çš„é—®é¢˜ï¼Œå»ºè®®ä½ å‘Šè¯‰æˆ‘å…·ä½“æƒ³äº†è§£å“ªä¸ªæ–¹é¢çš„è®­ç»ƒï¼Œæˆ‘ä¼šä¸ºä½ æä¾›æ›´è¯¦ç»†çš„æŒ‡å¯¼ã€‚"

    def generate_training_plan(self, student_analysis: Dict, recommended_actions: List[Dict]) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–è®­ç»ƒè®¡åˆ’"""
        try:
            prompt = f"""
åŸºäºä»¥ä¸‹å­¦ç”Ÿä½“æµ‹åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„ä¸ªæ€§åŒ–è®­ç»ƒè®¡åˆ’ï¼š

å­¦ç”Ÿä¿¡æ¯ï¼š
- æ€»åˆ†ï¼š{student_analysis.get('total_score', 0)}åˆ†
- æ•´ä½“æ°´å¹³ï¼š{student_analysis.get('overall_assessment', 'æœªçŸ¥')}
- éœ€è¦åŠ å¼ºçš„é¡¹ç›®ï¼š{[item['item'] for item in student_analysis.get('weak_items', [])]}

æ¨èåŠ¨ä½œï¼š{[action['action_name'] for action in recommended_actions[:5]]}

è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å«ä»¥ä¸‹å†…å®¹çš„è®­ç»ƒè®¡åˆ’ï¼š
1. è®­ç»ƒç›®æ ‡
2. æ¯å‘¨è®­ç»ƒå®‰æ’
3. å…·ä½“è®­ç»ƒå†…å®¹
4. æ³¨æ„äº‹é¡¹
5. é¢„æœŸæ•ˆæœ

è¯·ç”¨æ¸©æš–é¼“åŠ±çš„è¯­æ°”ï¼Œæä¾›å®ç”¨çš„å»ºè®®ã€‚
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ç”Ÿæˆè®­ç»ƒè®¡åˆ’å¤±è´¥: {e}")
            return self._get_default_training_plan(student_analysis, recommended_actions)
    
    def _get_default_training_plan(self, student_analysis: Dict, recommended_actions: List[Dict]) -> str:
        """è·å–é»˜è®¤è®­ç»ƒè®¡åˆ’"""
        plan = f"åŸºäºä½ çš„ä½“æµ‹åˆ†æï¼ˆæ€»åˆ†{student_analysis.get('total_score', 0)}åˆ†ï¼‰ï¼Œæˆ‘ä¸ºä½ åˆ¶å®šä»¥ä¸‹è®­ç»ƒè®¡åˆ’ï¼š\n\n"
        
        plan += "ğŸ¯ è®­ç»ƒç›®æ ‡ï¼š\n"
        if student_analysis.get('weak_items'):
            for item in student_analysis['weak_items'][:3]:
                plan += f"- æå‡{item['item']}æˆç»©\n"
        else:
            plan += "- ä¿æŒç°æœ‰æ°´å¹³ï¼Œå…¨é¢å‘å±•\n"
        
        plan += "\nğŸ“… æ¯å‘¨è®­ç»ƒå®‰æ’ï¼š\n"
        plan += "- å‘¨ä¸€ã€ä¸‰ã€äº”ï¼šåŠ›é‡è®­ç»ƒ\n"
        plan += "- å‘¨äºŒã€å››ï¼šæœ‰æ°§è®­ç»ƒ\n"
        plan += "- å‘¨å…­ï¼šæŸ”éŸ§æ€§è®­ç»ƒ\n"
        plan += "- å‘¨æ—¥ï¼šä¼‘æ¯\n"
        
        plan += "\nğŸ’ª æ¨èåŠ¨ä½œï¼š\n"
        for i, action in enumerate(recommended_actions[:3], 1):
            plan += f"{i}. {action['action_name']} - {action['sets']}ç»„Ã—{action['duration']}\n"
        
        plan += "\nâš ï¸ æ³¨æ„äº‹é¡¹ï¼š\n"
        plan += "- å¾ªåºæ¸è¿›ï¼Œä¸è¦æ€¥äºæ±‚æˆ\n"
        plan += "- æ³¨æ„åŠ¨ä½œæ ‡å‡†æ€§\n"
        plan += "- ä¿è¯å……è¶³ä¼‘æ¯å’Œè¥å…»\n"
        plan += "- å¦‚æœ‰ä¸é€‚ç«‹å³åœæ­¢\n"
        
        return plan
